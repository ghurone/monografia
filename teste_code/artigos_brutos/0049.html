<!DOCTYPE html>
<div class="articleTxt">
 <div class="articleBadge-editionMeta-doi-copyLink">
  <span class="_articleBadge">
   Artigos Gerais
  </span>
  <span class="_separator">
   •
  </span>
  <span class="_editionMeta">
   Rev. Bras. Ensino Fís. 44
   <span class="_separator">
    •
   </span>
   2022
  </span>
  <span class="_separator">
   •
  </span>
  <span class="group-doi">
   <a class="_doi" href="https://doi.org/10.1590/1806-9126-RBEF-2022-0214" target="_blank">
    https://doi.org/10.1590/1806-9126-RBEF-2022-0214
   </a>
   <a class="copyLink" data-clipboard-text="https://doi.org/10.1590/1806-9126-RBEF-2022-0214">
    <span class="sci-ico-link">
    </span>
    copiar
   </a>
  </span>
 </div>
 <h1 class="article-title">
  <span class="sci-ico-openAccess showTooltip" data-original-title="by 4.0 deed.en" data-toggle="tooltip">
  </span>
  Introduzindo aprendizado de máquina em cursos de física: o caso do rolamento no plano inclinado
  <a class="short-link" href="#" id="shorten">
   <span class="sci-ico-link">
   </span>
  </a>
 </h1>
 <h2 class="article-title">
  Inserting machine learning in physics courses: the case of rolling on an inclined plane
 </h2>
 <div class="articleMeta">
 </div>
 <div class="contribGroup">
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor1">
    <span>
     H. Ferreira
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor1" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    <div class="corresp">
     *Endereço de correspondência:
     <a href="mailto:hfsantos@ufabc.edu.br">
      hfsantos@ufabc.edu.br
     </a>
    </div>
    Universidade Federal do ABC, Centro de Ciências Naturais e Humanas, Santo André, SP, Brasil.Faculdade de Informática e Administração Paulista, São Paulo, SP, Brasil.
    <a class="btnContribLinks orcid" href="http://orcid.org/0000-0003-3309-2098">
     http://orcid.org/0000-0003-3309-2098
    </a>
   </ul>
  </span>
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor2">
    <span>
     E.F. Almeida Junior
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor2" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    Universidade Federal do Oeste da Bahia, Centro das Ciências Exatas e das Tecnologias, Barreiras, BA, Brasil.
    <a class="btnContribLinks orcid" href="http://orcid.org/0000-0001-8685-5007">
     http://orcid.org/0000-0001-8685-5007
    </a>
   </ul>
  </span>
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor3">
    <span>
     W. Espinosa-García
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor3" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    Universidad de San Buenaventura-Medellín, Facultad de Ingenierías, Medellín, ANT, Colombia.
    <a class="btnContribLinks orcid" href="http://orcid.org/0000-0003-4597-6333">
     http://orcid.org/0000-0003-4597-6333
    </a>
   </ul>
  </span>
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor4">
    <span>
     E. Novais
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor4" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    Universidade Federal do ABC, Centro de Ciências Naturais e Humanas, Santo André, SP, Brasil.
   </ul>
  </span>
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor5">
    <span>
     J.N.B. Rodrigues
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor5" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    Universidade Federal do ABC, Centro de Ciências Naturais e Humanas, Santo André, SP, Brasil.
   </ul>
  </span>
  <span class="dropdown">
   <a class="dropdown-toggle" data-toggle="dropdown" id="contribGroupTutor6">
    <span>
     G.M. Dalpian
    </span>
   </a>
   <ul aria-labelledby="contribGrupoTutor6" class="dropdown-menu" role="menu">
    <strong>
    </strong>
    Universidade Federal do ABC, Centro de Ciências Naturais e Humanas, Santo André, SP, Brasil.
    <a class="btnContribLinks orcid" href="http://orcid.org/0000-0001-5561-354X">
     http://orcid.org/0000-0001-5561-354X
    </a>
   </ul>
  </span>
  <a class="outlineFadeLink" data-target="#ModalTutors" data-toggle="modal" href="">
   Sobre os autores
  </a>
 </div>
 <div class="row">
  <ul class="col-md-2 hidden-sm articleMenu">
  </ul>
  <article class="col-md-10 col-md-offset-2 col-sm-12 col-sm-offset-0" id="articleText">
   <div class="articleSection" data-anchor="Resumos">
    <h1 class="articleSectionTitle">
     Resumos
    </h1>
   </div>
   <div>
    <p>
     Em uma ciência cada vez mais orientada a dados, o uso de métodos computacionais inteligentes é progressivamente indispensável. Neste contexto, torna-se importante expor os estudantes de graduação em física às metodologias de inteligência artificial e aprendizado de máquina. Neste trabalho propomos uma forma de utilizar tais métodos na física, resolvendo o problema didático do rolamento em um plano inclinado. Para tanto, introduzimos os principais conceitos das técnicas de aprendizado de máquina e realizamos medidas do tempo que diferentes objetos (aro, disco e esfera) levam para percorrer uma certa distância, de acordo com a altura inicial e o ângulo de inclinação do plano. Com estes dados, aplicamos métodos de classificação capazes de predizer o objeto que rolava sobre o plano com acurácia de 83%, e métodos de regressão capazes de prever a velocidade média do objeto com erro absoluto médio de 1.4 cm s
     <sup>
      −1
     </sup>
     . Mostramos também que este modelo didático é instrutivo pois possibilita uma comparação direta com modelos físicos tradicionais e serve como exemplo introdutório para a discussão do que significa ensinar física para o computador.
    </p>
    <p>
     <strong>
      Palavras-chave:
     </strong>
     <br/>
     Inteligência Artificial; Aprendizado de Máquina; Plano Inclinado
    </p>
   </div>
   <hr/>
   <div>
    <p>
     In an increasingly data-oriented science, the use of automatic computational methods is progressively indispensable. In this context, it becomes important to expose undergraduate physics students to artificial intelligence and machine learning methodologies. In this work we propose a way to use such methods in physics, solving the didactic problem of rolling on an inclined plane. We introduce the main concepts of machine learning techiniques and measure the travel time of different objects (rim, disk and sphere) for an initial height and tilt angle. Based on these data, we used classification models capable of predicting the object that was dropped with an accuracy of 83%, and regression models which were able to predict the average speed of the object that was rolled with mean absolute error of 1.4 cm s
     <sup>
      −1
     </sup>
     . We also show that this didactic model is instructive because it allows a direct comparison with physical models and serves as a discussion of the meaning of teaching physics to the computer.
    </p>
    <p>
     <strong>
      Keywords:
     </strong>
     <br/>
     Artificial Intelligence; Machine Learning; Inclined Plane
    </p>
   </div>
   <hr/>
   <div class="articleSection" data-anchor="Text">
    <h1 class="articleSectionTitle">
     1. Introdução
    </h1>
    <p>
     Algoritmos computacionais relacionadas à inteligência artificial já se tornaram corriqueiros no nosso dia a dia. Eles são responsáveis por nos sugerir o filme que vamos assistir, a música que iremos ouvir ou o livro que iremos comprar [
     <span class="ref">
      <sup class="xref xrefblue">
       1
      </sup>
      <span class="refCtt closed">
       <span>
        [1] F. Ricci, L. Rokach e B. Shapira (eds), Recommender systems handbook (Springer, New York, 2015), 2 ed.
       </span>
      </span>
     </span>
     ]. Da mesma forma, nas ciências naturais, o uso de técnicas associadas ao
     <i>
      big data
     </i>
     também tem se tornado habitual [
     <span class="ref">
      <sup class="xref xrefblue">
       2
      </sup>
      <span class="refCtt closed">
       <span>
        [2] G.R. Schleder, A.C.M. Padilha, C.M. Acosta, M. Costa e A. Fazzio, Journal of Physics: Materials 2, 032001 (2019).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       3
      </sup>
      <span class="refCtt closed">
       <span>
        [3] O.N. Oliveira Jr e M.C.F. Oliveira, Front. Chem. 10, 930369 (2022).
       </span>
      </span>
     </span>
     ]. Do ponto de vista do mercado de trabalho, os profissionais formados na área de física e engenharia também começam a encontrar lugar mais frequente em posições relacionadas à ciência de dados. Esse contexto contrasta com o fato de que a maioria dos cursos de física ainda não possuem esses temas incorporados no seu currículo. Disciplinas de Física Computacional, muito comuns em cursos de graduação em física, normalmente focam em temas mais tradicionais, como a solução de equações diferenciais, métodos de integração e métodos de Monte Carlo (ver Apêndice A para uma discussão mais detalhada sobre as ementas das disciplinas de física computacional em universidades federais brasileiras). Um bom exemplo de inserção de inteligência artificial em cursos de graduação pode ser encontrado na proposta pedagógica da Ilum (CNPEM), que é um bacharelado de ciência e tecnologia, e contempla em todos os semestres (desde o primeiro) disciplinas sobre programação e ciência de dados, com ênfase em aprendizado de máquina. Como o foco do curso é na interdisciplinaridade, os conceitos aprendidos de programação e ciência de dados são aplicados nas ciências biológicas e da matéria [
     <span class="ref">
      <sup class="xref xrefblue">
       4
      </sup>
      <span class="refCtt closed">
       <span>
        [4] S. Schmidt. Escola Superior Ilum busca cientísta do futuro, Revista FAPESP, junho de 2022.
       </span>
      </span>
     </span>
     ]. Neste artigo oferecemos um exemplo concreto de como inserir técnicas de inteligência artificial em cursos de graduação em física, focando no problema do rolamento em um plano inclinado. A utilização dessas metodologias em um exemplo conhecido e bem estabelecido potencializará sua aplicação em outros exemplos mais complexos e exploratórios.
    </p>
    <p>
     O problema do plano inclinado foi inicialmente analisado vários séculos atrás. Em 1638, no seu livro
     <i>
      Discursos sobre as Duas Novas Ciências
     </i>
     , Galileo Galilei apresentou um experimento no qual rolou uma esfera de bronze sobre uma peça de madeira inclinada em relação ao chão [
     <span class="ref">
      <sup class="xref xrefblue">
       5
      </sup>
      <span class="refCtt closed">
       <span>
        [5] G. Galilei, Dialogues Concerning Two New Sciences (Macmillan, New York, 1914).
       </span>
      </span>
     </span>
     ]. Dessas observações experimentais, Galileo concluiu que a distância percorrida pela esfera é proporcional ao quadrado do tempo transcorrido durante o movimento. Hoje esse conceito é amplamente difundido em capítulos de cinemática de livros didáticos de ensino médio e graduação [
     <span class="ref">
      <sup class="xref xrefblue">
       6
      </sup>
      <span class="refCtt closed">
       <span>
        [6] C.M. Ramos e J.R. Bonjorno, Fisica: História e Cotidiano (FTD, São Paulo, 2005).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       7
      </sup>
      <span class="refCtt closed">
       <span>
        [7] H.M. Nussenzveig, Curso de Física Básica: Mecânica (Blucher, Rio de Janeiro, 2013).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       8
      </sup>
      <span class="refCtt closed">
       <span>
        [8] A. Chaves e J.F. Sampaio, Física Básica: Mecânica (LTC, Rio de Janeiro, 2011).
       </span>
      </span>
     </span>
     ], normalmente sob o título de movimento retilíneo uniformemente variado.
    </p>
    <p>
     Apesar de sua simplicidade, o experimento do plano inclinado é um problema de física fundamental de grande riqueza conceitual. Não só é possível estabelecer leis do movimento de translação dos corpos, como também propriedades da rotação, como o momento de inércia. É possível verificar a conservação de energia quando as superfícies são polidas, como no caso de Galileo, ou estabelecer a perda de energia quando usado um plano rugoso com atrito. Neste caso, o experimento do plano inclinado também pode ser usado para estabelecer os coeficientes de atrito estático e dinâmico entre a superfície e o corpo de prova [
     <span class="ref">
      <sup class="xref xrefblue">
       9
      </sup>
      <span class="refCtt closed">
       <span>
        [9] R.L. Chaplin e M.G. Miller, American Journal of Physics 52, 1108 (1984).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       10
      </sup>
      <span class="refCtt closed">
       <span>
        [10] R. Cross, European Journal of Physics 36, 065047 (2015).
       </span>
      </span>
     </span>
     ]. Sendo um experimento tão rico, ele é comumente explorado em exercícios e nos laboratórios didáticos dos cursos de física e engenharia.
    </p>
    <p>
     A Física Computacional, por sua vez, demorou mais de trezentos anos depois de Galileo para surgir como área do conhecimento. Tradicionalmente, os livros-texto dessa disciplina focam em métodos de cálculo numérico para solução de problemas matematicamente bem estabelecidos, como soluções de equações diferenciais e análise de Fourier [
     <span class="ref">
      <sup class="xref xrefblue">
       11
      </sup>
      <span class="refCtt closed">
       <span>
        [11] M. Newman, Computational Physics (Createspace Independent Publishing Platform, North Charleston, 2012).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       12
      </sup>
      <span class="refCtt closed">
       <span>
        [12] D. Walker, Computational Physics (Mercury Learning &amp; Information, Dulles, 2016).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       13
      </sup>
      <span class="refCtt closed">
       <span>
        [13] P.O.J. Scherer, Computational Physics (Springer, Cham, 2017).
       </span>
      </span>
     </span>
     ]. Por outro lado, os avanços na ciência da computação suprem novos métodos computacionais para solução de problemas com abordagens muito diferentes daquelas comumente exploradas na física. Em especial, a inteligência artificial e a mineração de dados tem se mostrado ferramentas capazes de acrescentar novos contornos aos paradigmas de fazer ciência [
     <span class="ref">
      <sup class="xref xrefblue">
       14
      </sup>
      <span class="refCtt closed">
       <span>
        [14] G.R. Schleder e A. Fazzio, Revista Brasileira de Ensino de Física 43, e20200407 (2021).
       </span>
      </span>
     </span>
     ]. Da mesma maneira que Galileo pode ser considerado como um representante arquetípico da transição entre a Ciência Empírica e a Ciência Teórica, a inteligência artificial é a ferramenta arquetípica da Ciência Orientada à Dados, o paradigma onde grandes volumes de dados podem ser medidos e/ou simulados, armazenados, acessados e processados para gerar conhecimento. Neste contexto, muitos livros de Física Computacional ainda se concentram somente no paradigma de Ciência Computacional Clássica (focada em simulações), deixando de lado os recentes avanços interdisciplinares do uso de inteligência artificial e outras técnicas da ciência da computação para afísica.
    </p>
    <p>
     Neste trabalho exploramos essa questão demonstrando que os conceitos de inteligência artificial, particularmente do subcampo do Aprendizado de Máquina, já podem ser incluídos em disciplinas de Física Computacional e que este ferramental estará cada vez mais presente no dia a dia de cientistas das mais variadas áreas. Para isso, introduzimos o uso de métodos de Aprendizado de Máquina no problema do plano inclinado de Galileo, demonstrando como podemos executar as tarefas básicas de regressão e classificação para um problema fundamental de física.
    </p>
    <p>
     Para apresentar esses conceitos, inicialmente discutimos, na Seção
     <strong>
      1.1
     </strong>
     , o modelo físico do plano inclinado. Já na Seção
     <strong>
      1.2
     </strong>
     é feita uma introdução aos principais conceitos do Aprendizado de Máquina. Como este é um tema complexo, não detalharemos ou deduziremos as equações relacionadas a essas metodologias, mas ofereceremos referências nas quais essas informações podem ser encontradas. Nas Seções
     <strong>
      2.1
     </strong>
     e
     <strong>
      2.2
     </strong>
     são apresentadas as metologias experimentais e computacionais utilizadas neste trabalho, respectivamente. O artigo se encerra com a apresentação dos principais resultados junto com a discussão sobre os principais problemas que podem ser observados na utilização desses métodos. As medidas realizadas envolvem rolar três objetos diferentes (aro, cilindro e esfera) em um plano inclinado, realizando medidas de tempo, ângulo e altura da qual o objeto foi largado. Munidos desses dados, escrevemos códigos de classificação que permitem prever qual objeto foi rolado e códigos de regressão que permitem prever a velocidade média dos objetos. Todos os dados medidos e utilizados neste trabalho, bem como os códigos que foram desenvolvidos para executar as simulações e obter os gráficos estão disponíveis como materialsuplementar.
    </p>
    <h2>
     1.1. Rolamento em plano inclinado
    </h2>
    <p>
     O problema do rolamento de um objeto sobre um plano inclinado é representado na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F1" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      1
     </a>
     . Os parâmetros relevantes para o experimento são a distância percorrida pelo objeto,
     <i>
      s
     </i>
     , o ângulo de inclinação do plano,
     <math display="inline">
      <mi>
       θ
      </mi>
     </math>
     , e o tempo de descida do objeto,
     <i>
      t
     </i>
     , devido a aceleração da gravidade,
     <math display="inline">
      <mrow>
       <mi>
        g
       </mi>
       <mo>
        ≈
       </mo>
       <mn>
        9.8
       </mn>
      </mrow>
     </math>
     <math display="inline">
      <mrow>
       <mi class="ltx_unit" mathvariant="normal">
        m
       </mi>
       <mtext>
       </mtext>
       <msup>
        <mi class="ltx_unit" mathvariant="normal">
         s
        </mi>
        <mrow>
         <mo>
          -
         </mo>
         <mn>
          2
         </mn>
        </mrow>
       </msup>
      </mrow>
     </math>
     .
    </p>
    <div class="row fig" id="S1_F1">
     <a name="S1_F1">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS1_F1" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/d546423598fe572d259b74966428ef597b87e8e0.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figura 1
      </strong>
      <br/>
      Ilustração do rolamento de um aro, um disco e uma esfera sobre um plano inclinado de um ângulo
      <math display="inline">
       <mi>
        θ
       </mi>
      </math>
      com relação ao plano horizontal. Na esfera são destacadas variáveis físicas de interesse (análogas para os outros objetos), como a força peso
      <i>
       mg
      </i>
      , a velocidade linear
      <i>
       v
      </i>
      <sub>
       <i>
        c
       </i>
      </sub>
      do centro de massa, a velocidade angular
      <math display="inline">
       <mi>
        ω
       </mi>
      </math>
      de giro em relação ao centro de massa e a distância
      <i>
       s
      </i>
      percorrida sobre a superfície a partir da origem do movimento a uma altura
      <math display="inline">
       <mrow>
        <mi>
         h
        </mi>
        <mo>
         =
        </mo>
        <mrow>
         <mi>
          s
         </mi>
         <mo>
          ⁢
         </mo>
         <mrow>
          <mi>
           sin
          </mi>
          <mo>
           ⁡
          </mo>
          <mi>
           θ
          </mi>
         </mrow>
        </mrow>
       </mrow>
      </math>
      .
      <br/>
     </div>
    </div>
    <p>
     Do ponto de vista físico o objeto é caracterizado por sua massa,
     <i>
      m
     </i>
     , e seu momento de inércia
     <i>
      I
     </i>
     , que no caso de objetos com simetria radial é
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E1">
     <a name="S1_E1">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (1)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mi>
           I
          </mi>
          <mo>
           =
          </mo>
          <mrow>
           <msub>
            <mo largeop="true" symmetric="true">
             ∫
            </mo>
            <mi>
             C
            </mi>
           </msub>
           <mrow>
            <msup>
             <mi>
              r
             </mi>
             <mn>
              2
             </mn>
            </msup>
            <mo>
             ⁢
            </mo>
            <mrow>
             <mo mathvariant="italic" rspace="0pt">
              d
             </mo>
             <mi>
              m
             </mi>
            </mrow>
           </mrow>
          </mrow>
          <mo>
           =
          </mo>
          <mrow>
           <mi>
            β
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <msup>
            <mi>
             R
            </mi>
            <mn>
             2
            </mn>
           </msup>
          </mrow>
         </mrow>
         <mo>
          ,
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     onde
     <i>
      R
     </i>
     é o raio dos três objetos que estamos considerando (esfera, disco e aro). Para a esfera maciça,
     <math display="inline">
      <mrow>
       <mi>
        β
       </mi>
       <mo>
        =
       </mo>
       <mfrac>
        <mn>
         2
        </mn>
        <mn>
         5
        </mn>
       </mfrac>
      </mrow>
     </math>
     ; para a casca esférica,
     <math display="inline">
      <mrow>
       <mi>
        β
       </mi>
       <mo>
        =
       </mo>
       <mfrac>
        <mn>
         2
        </mn>
        <mn>
         3
        </mn>
       </mfrac>
      </mrow>
     </math>
     ; para o disco ou cilindro,
     <math display="inline">
      <mrow>
       <mi>
        β
       </mi>
       <mo>
        =
       </mo>
       <mfrac>
        <mn>
         1
        </mn>
        <mn>
         2
        </mn>
       </mfrac>
      </mrow>
     </math>
     ; e para o aro,
     <math display="inline">
      <mrow>
       <mi>
        β
       </mi>
       <mo>
        =
       </mo>
       <mn>
        1
       </mn>
      </mrow>
     </math>
     .
    </p>
    <p>
     Em excelente aproximação podemos considerar a conservação de energia e escrever que:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E2">
     <a name="S1_E2">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (2)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mrow>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            g
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            h
           </mi>
          </mrow>
          <mo>
           =
          </mo>
          <mrow>
           <mrow>
            <mfrac>
             <mn>
              1
             </mn>
             <mn>
              2
             </mn>
            </mfrac>
            <mo>
             ⁢
            </mo>
            <mi>
             m
            </mi>
            <mo>
             ⁢
            </mo>
            <msup>
             <mi>
              v
             </mi>
             <mn>
              2
             </mn>
            </msup>
           </mrow>
           <mo>
            +
           </mo>
           <mrow>
            <mfrac>
             <mn>
              1
             </mn>
             <mn>
              2
             </mn>
            </mfrac>
            <mo>
             ⁢
            </mo>
            <mi>
             I
            </mi>
            <mo>
             ⁢
            </mo>
            <msup>
             <mi>
              ω
             </mi>
             <mn>
              2
             </mn>
            </msup>
           </mrow>
          </mrow>
         </mrow>
         <mo>
          ,
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     onde a parcela à esquerda representa a energia potencial gravitacional inicial do objeto e a parcela à direta, a energia cinética translacional e rotacional final do objeto.
    </p>
    <p>
     Assumindo que o objeto rola sem deslizar, a velocidade linear do centro de massa,
     <i>
      v
     </i>
     <sub>
      <i>
       c
      </i>
     </sub>
     , e a velocidade tangencial,
     <math display="inline">
      <mrow>
       <msub>
        <mi>
         v
        </mi>
        <mi>
         t
        </mi>
       </msub>
       <mo>
        =
       </mo>
       <mrow>
        <mi>
         R
        </mi>
        <mo>
         ⁢
        </mo>
        <mi>
         ω
        </mi>
       </mrow>
      </mrow>
     </math>
     , são exatamente iguais,
     <math display="inline">
      <mrow>
       <msub>
        <mi>
         v
        </mi>
        <mi>
         c
        </mi>
       </msub>
       <mo>
        =
       </mo>
       <msub>
        <mi>
         v
        </mi>
        <mi>
         t
        </mi>
       </msub>
       <mo>
        =
       </mo>
       <mrow>
        <mi>
         R
        </mi>
        <mo>
         ⁢
        </mo>
        <mi>
         ω
        </mi>
       </mrow>
      </mrow>
     </math>
     (onde
     <math display="inline">
      <mi>
       ω
      </mi>
     </math>
     é a velocidade angular de rotação do objeto). Assim podemos reescrever a Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E2" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      2
     </a>
     como:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E3">
     <a name="S1_E3">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (3)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mrow>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            g
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            h
           </mi>
          </mrow>
          <mo>
           =
          </mo>
          <mrow>
           <mfrac>
            <mn>
             1
            </mn>
            <mn>
             2
            </mn>
           </mfrac>
           <mo>
            ⁢
           </mo>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <msup>
            <mi>
             v
            </mi>
            <mn>
             2
            </mn>
           </msup>
           <mo>
            ⁢
           </mo>
           <mrow>
            <mo stretchy="false">
             (
            </mo>
            <mrow>
             <mn>
              1
             </mn>
             <mo>
              +
             </mo>
             <mi>
              β
             </mi>
            </mrow>
            <mo stretchy="false">
             )
            </mo>
           </mrow>
          </mrow>
         </mrow>
         <mo>
          ,
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     e a velocidade máxima final
     <i>
      v
     </i>
     <sub>
      <i>
       f
      </i>
     </sub>
     alcançada ao final do percurso
     <i>
      s
     </i>
     para uma altura inicial
     <i>
      h
     </i>
     será:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E4">
     <a name="S1_E4">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (4)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <msub>
           <mi>
            v
           </mi>
           <mi>
            f
           </mi>
          </msub>
          <mo>
           =
          </mo>
          <msqrt>
           <mfrac>
            <mrow>
             <mn>
              2
             </mn>
             <mo>
              ⁢
             </mo>
             <mi>
              g
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              h
             </mi>
            </mrow>
            <mrow>
             <mn>
              1
             </mn>
             <mo>
              +
             </mo>
             <mi>
              β
             </mi>
            </mrow>
           </mfrac>
          </msqrt>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     Para uma aceleração constante, a velocidade final
     <i>
      v
     </i>
     <sub>
      <i>
       f
      </i>
     </sub>
     é exatamente o dobro da velocidade média
     <i>
      v
      <sub>
       med
      </sub>
     </i>
     . no percurso (uma demonstração disso é fornecida no Apêndice B do material suplementar), de forma que podemos concluir que:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E5">
     <a name="S1_E5">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (5)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <msub>
           <mi>
            v
           </mi>
           <mrow>
            <mi>
             m
            </mi>
            <mo>
             ⁢
            </mo>
            <mi>
             e
            </mi>
            <mo>
             ⁢
            </mo>
            <mi>
             d
            </mi>
           </mrow>
          </msub>
          <mo>
           =
          </mo>
          <mrow>
           <mfrac>
            <mn>
             1
            </mn>
            <mn>
             2
            </mn>
           </mfrac>
           <mo>
            ⁢
           </mo>
           <msqrt>
            <mfrac>
             <mrow>
              <mn>
               2
              </mn>
              <mo>
               ⁢
              </mo>
              <mi>
               g
              </mi>
              <mo>
               ⁢
              </mo>
              <mi>
               h
              </mi>
             </mrow>
             <mrow>
              <mn>
               1
              </mn>
              <mo>
               +
              </mo>
              <mi>
               β
              </mi>
             </mrow>
            </mfrac>
           </msqrt>
          </mrow>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     A Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E5" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      5
     </a>
     é, portanto, um modelo analítico preditivo do comportamento cinemático de objetos de massa uniformemente distribuída e simetria radial, que rolam sem deslizar sobre um plano inclinado. A princípio, com essa equação, dado
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <mi>
        h
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        θ
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        β
       </mi>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     podemos predizer
     <i>
      v
      <sub>
       med
      </sub>
     </i>
     , ou, dado
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <mi>
        h
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        θ
       </mi>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         v
        </mi>
        <mrow>
         <mi>
          m
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          e
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          d
         </mi>
        </mrow>
       </msub>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     predizer
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     . Usaremos exatamente essas duas possibilidades para explorar a aplicação de aprendizado de máquina supervisionado para predizer
     <i>
      v
      <sub>
       med
      </sub>
     </i>
     (tarefa de regressão) e predizer o objeto, o que é análogo a predizer
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     (tarefa de classificação).
    </p>
    <p>
     Contudo, tal formulação não considera um parâmetro fenomenológico importante para o modelo físico, o coeficiente de atrito,
     <math display="inline">
      <mi>
       μ
      </mi>
     </math>
     , entre o objeto e a superfície do plano (que como depende da área de contato também é função da forma do objeto). É o atrito entre o objeto e a superfície que produz o torque que faz o objeto entrar em rotação. Se o atrito fosse zero, o objeto simplesmente deslizaria. No limite oposto, o objeto rola sem deslizar, quando a velocidade do centro de massa é igual a velocidade tangencial da superfície do objeto. A situação experimental em geral está entre esses dois limites físicos. Podemos modelar isso através de um coeficiente
     <i>
      f
     </i>
     , tal que
     <i>
      v
     </i>
     <sub>
      <i>
       t
      </i>
     </sub>
     =
     <i>
      f
     </i>
     v
     <sub>
      <i>
       c
      </i>
     </sub>
     , de maneira que
     <i>
      f = 1
     </i>
     corresponde a situação na qual o objeto rolou sem deslizar, e
     <math display="inline">
      <mrow>
       <mn>
        0
       </mn>
       <mo>
        &lt;
       </mo>
       <mi>
        f
       </mi>
       <mo>
        ≤
       </mo>
       <mn>
        1
       </mn>
      </mrow>
     </math>
     , a situação de rolar e deslizar concomitantemente. Dessa forma, a Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E3" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      3
     </a>
     poderia ser reescrita como:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E6">
     <a name="S1_E6">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (6)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mrow>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            g
           </mi>
           <mo>
            ⁢
           </mo>
           <mi>
            h
           </mi>
          </mrow>
          <mo>
           =
          </mo>
          <mrow>
           <mfrac>
            <mn>
             1
            </mn>
            <mn>
             2
            </mn>
           </mfrac>
           <mo>
            ⁢
           </mo>
           <mi>
            m
           </mi>
           <mo>
            ⁢
           </mo>
           <mmultiscripts>
            <mi>
             v
            </mi>
            <mi>
             c
            </mi>
            <none>
            </none>
            <none>
            </none>
            <mn>
             2
            </mn>
           </mmultiscripts>
           <mo>
            ⁢
           </mo>
           <mrow>
            <mo stretchy="false">
             (
            </mo>
            <mrow>
             <mn>
              1
             </mn>
             <mo>
              +
             </mo>
             <mrow>
              <mi>
               β
              </mi>
              <mo>
               ⁢
              </mo>
              <msup>
               <mi>
                f
               </mi>
               <mn>
                2
               </mn>
              </msup>
             </mrow>
            </mrow>
            <mo stretchy="false">
             )
            </mo>
           </mrow>
          </mrow>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     Lembrando que
     <math display="inline">
      <mrow>
       <mi>
        h
       </mi>
       <mo>
        =
       </mo>
       <mrow>
        <mi>
         s
        </mi>
        <mo>
         ⁢
        </mo>
        <mrow>
         <mi>
          sin
         </mi>
         <mo>
          ⁡
         </mo>
         <mrow>
          <mo stretchy="false">
           (
          </mo>
          <mi>
           θ
          </mi>
          <mo stretchy="false">
           )
          </mo>
         </mrow>
        </mrow>
       </mrow>
      </mrow>
     </math>
     e que
     <math display="inline">
      <mrow>
       <msub>
        <mi>
         v
        </mi>
        <mi>
         c
        </mi>
       </msub>
       <mo>
        =
       </mo>
       <mrow>
        <mn>
         2
        </mn>
        <mo>
         ⁢
        </mo>
        <msub>
         <mi>
          v
         </mi>
         <mrow>
          <mi>
           m
          </mi>
          <mo>
           ⁢
          </mo>
          <mi>
           e
          </mi>
          <mo>
           ⁢
          </mo>
          <mi>
           d
          </mi>
         </mrow>
        </msub>
       </mrow>
       <mo>
        =
       </mo>
       <mrow>
        <mn>
         2
        </mn>
        <mo>
         ⁢
        </mo>
        <mfrac>
         <mi>
          s
         </mi>
         <mi>
          t
         </mi>
        </mfrac>
       </mrow>
      </mrow>
     </math>
     :
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E7">
     <a name="S1_E7">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (7)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mrow>
           <mi>
            β
           </mi>
           <mo>
            ⁢
           </mo>
           <msup>
            <mi>
             f
            </mi>
            <mn>
             2
            </mn>
           </msup>
          </mrow>
          <mo>
           =
          </mo>
          <mrow>
           <mfrac>
            <mrow>
             <mi>
              g
             </mi>
             <mo>
              ⁢
             </mo>
             <msup>
              <mi>
               t
              </mi>
              <mn>
               2
              </mn>
             </msup>
             <mo>
              ⁢
             </mo>
             <mrow>
              <mi>
               sin
              </mi>
              <mo>
               ⁡
              </mo>
              <mrow>
               <mo stretchy="false">
                (
               </mo>
               <mi>
                θ
               </mi>
               <mo stretchy="false">
                )
               </mo>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mn>
              2
             </mn>
             <mo>
              ⁢
             </mo>
             <mi>
              s
             </mi>
            </mrow>
           </mfrac>
           <mo>
            -
           </mo>
           <mn>
            1
           </mn>
          </mrow>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <div class="row fig" id="S1_F2">
     <a name="S1_F2">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS1_F2" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/4b7be4a67b2ab614c64dc3aefaf279f515386ed4.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figura 2
      </strong>
      <br/>
      Aprendizado de Máquina: (a) Etapas para a utilização de técnicas de aprendizado de máquina (a seta vermelha simboliza o fluxo direto de trabalho e as setas em preto, o retorno às etapas anteriores visando o aperfeiçoamento); (b) Particionamento das técnicas de aprendizado de máquina que são usadas na etapa de modelagem (a), separadas de acordo com as estratégias de aprendizado (em verde) e o tipo de tarefa resolvida pelo algoritmo (em amarelo).
      <br/>
     </div>
    </div>
    <p>
     Por outro lado, usando a segunda lei de Newton,
     <i>
      F
     </i>
     =
     <i>
      ma
     </i>
     <sub>
      <i>
       c
      </i>
     </sub>
     e
     <math display="inline">
      <mrow>
       <mi>
        τ
       </mi>
       <mo>
        =
       </mo>
       <mrow>
        <mi>
         I
        </mi>
        <mo>
         ⁢
        </mo>
        <mfrac>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           t
          </mi>
         </msub>
         <mi>
          R
         </mi>
        </mfrac>
       </mrow>
      </mrow>
     </math>
     , as acelerações do centro de massa,
     <i>
      a
     </i>
     <sub>
      <i>
       c
      </i>
     </sub>
     , e tangencial,
     <i>
      a
      <sub>
       t
      </sub>
     </i>
     , do corpo girante que está descendo o plano inclinado são calculadas por:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E8">
     <a name="S1_E8">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (8)
       </span>
       <math display="block">
        <mrow>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           c
          </mi>
         </msub>
         <mo>
          =
         </mo>
         <mi>
          g
         </mi>
         <mi>
          sin
         </mi>
         <mo stretchy="false">
          (
         </mo>
         <mi>
          θ
         </mi>
         <mo stretchy="false">
          )
         </mo>
         <mo>
          −
         </mo>
         <mi>
          μ
         </mi>
         <mi>
          g
         </mi>
         <mi>
          cos
         </mi>
         <mo stretchy="false">
          (
         </mo>
         <mi>
          θ
         </mi>
         <mo stretchy="false">
          ),
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <div class="row formula" id="eS1_E9">
     <a name="S1_E9">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (9)
       </span>
       <math display="block">
        <msub>
         <mi>
          a
         </mi>
         <mi>
          t
         </mi>
        </msub>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi>
           μ
          </mi>
          <mi>
           g
          </mi>
         </mrow>
         <mi>
          β
         </mi>
        </mfrac>
        <mi>
         cos
        </mi>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         θ
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         .
        </mo>
       </math>
      </div>
     </div>
    </div>
    <p>
     Logo, as velocidades podem ser expressas por: An error in the conversion from LaTeX to XML has occurred here.
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E10">
     <a name="S1_E10">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (10)
       </span>
       <math display="block">
        <msub>
         <mi>
          v
         </mi>
         <mi>
          c
         </mi>
        </msub>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          a
         </mi>
         <mi>
          c
         </mi>
        </msub>
        <mi>
         t
        </mi>
        <mo>
         =
        </mo>
        <mi>
         g
        </mi>
        <mi>
         t
        </mi>
        <mi>
         sin
        </mi>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         θ
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         −
        </mo>
        <mi>
         μ
        </mi>
        <mi>
         g
        </mi>
        <mi>
         t
        </mi>
        <mi>
         cos
        </mi>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         θ
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         ,
        </mo>
       </math>
      </div>
     </div>
    </div>
    <div class="row formula" id="eS1_E11">
     <a name="S1_E11">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (11)
       </span>
       <math display="block">
        <msub>
         <mi>
          v
         </mi>
         <mi>
          t
         </mi>
        </msub>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          a
         </mi>
         <mi>
          t
         </mi>
        </msub>
        <mi>
         t
        </mi>
        <mo>
         =
        </mo>
        <mfrac>
         <mrow>
          <mi>
           μ
          </mi>
          <mi>
           g
          </mi>
          <mi>
           t
          </mi>
         </mrow>
         <mi>
          β
         </mi>
        </mfrac>
        <mi>
         cos
        </mi>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         θ
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         .
        </mo>
       </math>
      </div>
     </div>
    </div>
    <p>
     Então o coeficiente
     <i>
      f
     </i>
     é:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E12">
     <a name="S1_E12">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (12)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mi>
           f
          </mi>
          <mo>
           =
          </mo>
          <mrow>
           <mfrac>
            <mn>
             1
            </mn>
            <mi>
             β
            </mi>
           </mfrac>
           <mo>
            ⁢
           </mo>
           <mfrac>
            <mi>
             μ
            </mi>
            <mrow>
             <mrow>
              <mi>
               tan
              </mi>
              <mo>
               ⁡
              </mo>
              <mrow>
               <mo stretchy="false">
                (
               </mo>
               <mi>
                θ
               </mi>
               <mo stretchy="false">
                )
               </mo>
              </mrow>
             </mrow>
             <mo>
              -
             </mo>
             <mi>
              μ
             </mi>
            </mrow>
           </mfrac>
          </mrow>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     Substituindo a Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E12" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      12
     </a>
     na Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E7" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      7
     </a>
     e usando novamente a equação para
     <i>
      a
     </i>
     <sub>
      <i>
       c
      </i>
     </sub>
     , encontramos:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS1_E13">
     <a name="S1_E13">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (13)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <mi>
           γ
          </mi>
          <mo>
           =
          </mo>
          <mfrac>
           <msup>
            <mi>
             μ
            </mi>
            <mn>
             2
            </mn>
           </msup>
           <mi>
            β
           </mi>
          </mfrac>
          <mo>
           =
          </mo>
          <mfrac>
           <mrow>
            <mrow>
             <mn>
              2
             </mn>
             <mo>
              ⁢
             </mo>
             <mi>
              s
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              g
             </mi>
             <mo>
              ⁢
             </mo>
             <msup>
              <mi>
               t
              </mi>
              <mn>
               2
              </mn>
             </msup>
             <mo>
              ⁢
             </mo>
             <mrow>
              <mi>
               sin
              </mi>
              <mo>
               ⁡
              </mo>
              <mrow>
               <mo stretchy="false">
                (
               </mo>
               <mi>
                θ
               </mi>
               <mo stretchy="false">
                )
               </mo>
              </mrow>
             </mrow>
            </mrow>
            <mo>
             -
            </mo>
            <mrow>
             <mn>
              4
             </mn>
             <mo>
              ⁢
             </mo>
             <msup>
              <mi>
               s
              </mi>
              <mn>
               2
              </mn>
             </msup>
            </mrow>
           </mrow>
           <mrow>
            <msup>
             <mi>
              g
             </mi>
             <mn>
              2
             </mn>
            </msup>
            <mo>
             ⁢
            </mo>
            <msup>
             <mi>
              t
             </mi>
             <mn>
              4
             </mn>
            </msup>
            <mo>
             ⁢
            </mo>
            <mrow>
             <msup>
              <mi>
               cos
              </mi>
              <mn>
               2
              </mn>
             </msup>
             <mo>
              ⁡
             </mo>
             <mrow>
              <mo stretchy="false">
               (
              </mo>
              <mi>
               θ
              </mi>
              <mo stretchy="false">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mfrac>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     A Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E13" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      13
     </a>
     é um modelo que relaciona a forma do objeto e o atrito característico dele com a superfície do plano inclinado com os parâmetros experimentais
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <mi>
        s
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        θ
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        t
       </mi>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     para uma condição arbitrária que pode misturar os movimentos de rolamento e deslizamento do objeto sobre o plano.
    </p>
    <p>
     Para uma abordagem diferente através de dinâmica Newtoniana, na qual o atrito é discutido explicitamente, recomendamos os trabalhos de Chaplin e Miller [
     <span class="ref">
      <sup class="xref xrefblue">
       9
      </sup>
      <span class="refCtt closed">
       <span>
        [9] R.L. Chaplin e M.G. Miller, American Journal of Physics 52, 1108 (1984).
       </span>
      </span>
     </span>
     ] e Cross [
     <span class="ref">
      <sup class="xref xrefblue">
       10
      </sup>
      <span class="refCtt closed">
       <span>
        [10] R. Cross, European Journal of Physics 36, 065047 (2015).
       </span>
      </span>
     </span>
     ]. Já uma discussão por mecânica Lagrangiana assumindo o vínculo de movimento é feita no Apêndice B deste trabalho.
    </p>
    <h2>
     1.2. Aprendizado de máquina
    </h2>
    <p>
     A área de Inteligência Artificial tem desenvolvido diferentes abordagens para a solução de problemas complexos através do uso de computadores. Dentre essas abordagens, o Aprendizado de Máquina visa desenvolver algoritmos que aprendam a generalizar soluções através de uma grande quantidade de exemplos sobre o problema. O termo é normalmente atribuído a Arthur Samuel, pioneiro nessa abordagem, que o define como a ciência de programar computadores para que eles aprendam através da experiência, eliminando assim a necessidade de uma programação detalhada [
     <span class="ref">
      <sup class="xref xrefblue">
       15
      </sup>
      <span class="refCtt closed">
       <span>
        [15] A.L. Samuel, IBM Journal of Research and Development 3, 210 (1959).
       </span>
      </span>
     </span>
     ]. Tais algoritmos, ditos de aprendizado, são, em geral, agnósticos ao tipo de problema resolvido, dependendo apenas dos dados fornecidos para encontrar uma solução.
    </p>
    <p>
     Apesar dessa virtual universalidade dos algoritmos, certas limitações e considerações prévias devem ser ponderadas para cada tipo de problema. Decidir os dados a serem coletados e como representá-los no computador é de fundamental importância, exigindo conhecimentos específicos sobre o domínio do problema e sobre o funcionamento dos algoritmos utilizados. Na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F2" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      2
     </a>
     (a) apresentamos uma metodologia de trabalho em ciência de dados e inteligência artificial.
    </p>
    <p>
     A representação dos dados é a representação do conhecimento que temos sobre o problema na forma de uma estrutura computacional. Por exemplo, informações visuais coloridas podem ser representadas em arquivos de imagens
     <i>
      bitmap
     </i>
     , que, de maneira simplificada, são estruturas de dados compostas por três matrizes de números inteiros, normalmente com cada elemento podendo ir de 0 a 255 de intensidade da cor, cada matriz representando uma cor do modelo aditivo RGB (vermelho, verde e azul), e cujas dimensões de largura e altura são exatamente a largura e a altura em
     <i>
      pixels
     </i>
     da imagem armazenada. Cada tupla ordenada
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <mi>
        R
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        G
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        B
       </mi>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     de números inteiros associada a um elemento
     <math display="inline">
      <mrow>
       <mi>
        i
       </mi>
       <mo>
        ,
       </mo>
       <mi>
        j
       </mi>
      </mrow>
     </math>
     das matrizes é denominada
     <i>
      pixel
     </i>
     da imagem. Este intrincado exemplo serve para mostrar o grau de sofisticação que uma representação de dado pode ter. Um algoritmo de aprendizado de máquina que opera sobre imagens deve ser construído de tal maneira a entender a representação aqui discutida ou a representação da imagem deve ser transformada para um formato compreensível ao padrão de entrada do algoritmo. Existem muitas outras formas de representar informação e conhecimento em computadores, como dicionários (ontologias), grafos e tabelas. Neste trabalho focamos na utilização de dados representados na forma tabular.
    </p>
    <p>
     Já a modelagem envolve a escolha e uso de algoritmos de aprendizado de máquina adequados para o tipo de problema que se quer resolver e com os dados disponíveis (quantidade, qualidade e representação). Os algoritmos podem se referir a modelos descritivos ou reditivos [
     <span class="ref">
      <sup class="xref xrefblue">
       16
      </sup>
      <span class="refCtt closed">
       <span>
        [16] K. Faceli, A.C. Lorena, J. Gama, T.A. Almeida e L.F.A.C.P.Carvalho, Inteligência Artificial – Uma Abordagem de Aprendizado de Máquina (LTC, Rio de Janeiro, 2021).
       </span>
      </span>
     </span>
     ]. Nesta etapa, além da escolha do algoritmo adequado, é feito o ajuste fino de seus hiperparâmetros, isto é, são configurados parâmetros internos de funcionamento do algoritmo que são independentes do problema a ser tratado, mas cujos valores podem ser otimizados para a solução pretendida. Quando se tem dados suficientes, é comum separar parte deles somente para realizar a otimização dos hiperparâmetros – este conjunto separado de dados é chamado de conjunto de validação [
     <span class="ref">
      <sup class="xref xrefblue">
       17
      </sup>
      <span class="refCtt closed">
       <span>
        [17] A. Géron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow (O’Reilly Media, Sebastopol, 2019), 2 ed.
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       18
      </sup>
      <span class="refCtt closed">
       <span>
        [18] A. Burkov, Machine learning engineering (True Positive, Quebec, 2020).
       </span>
      </span>
     </span>
     ]. Por outro lado, para a escolha do algoritmo é necessário compreender as estratégias usadas e as tarefas que podem ser realizadas. Na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F2" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      2
     </a>
     (b) são apresentadas as principais estratégias de aprendizado: para a
     <i>
      abordagem supervisionada
     </i>
     , os dados utilizados devem ser instâncias de um problema contendo uma resposta conhecida, denominada rótulo; no caso
     <i>
      não supervisionado
     </i>
     , não existem informações sobre a resposta esperada; métodos de
     <i>
      aprendizado por reforço
     </i>
     também não possuem rótulos para os exemplos, entretanto possuem um sinal de feedback que deve ser otimizado durante cada interação de coleta de dados; já no
     <i>
      aprendizado semi-supervisionado
     </i>
     , são utilizados métodos supervisionados e não supervisionados em série ou paralelo para realizar a tarefa desejada.
    </p>
    <p>
     Das tarefas que os algoritmos podem resolver (Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F2" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      2
     </a>
     (b)): a
     <i>
      regressão
     </i>
     envolve descobrir uma forma de relacionar a entrada
     <i>
      X
     </i>
     com a saída
     <i>
      Y
     </i>
     , sendo ambas, em geral, variáveis numéricas; na
     <i>
      classificação
     </i>
     , apesar da entrada ser numérica (contínua ou discreta), a saída é discreta ou categórica (um número ou palavra que define a classe alvo)
     <span class="ref footnote">
      <sup class="xref">
       1
      </sup>
      <span class="refCtt closed">
       <span class="refCttPadding">
        <strong class="fn-title">
         1
        </strong>
        Em todos os casos discutidos, técnicas de pré-processamento da entrada podem ser usadas para adequar entradas simbólicas para numéricas, como o Label Encoding e o One Hot Encoding, etapa essa denominada de transformação de dados [16]. Algoritmos de Árvore de Decisão podem ser diretamente implementados para usarem dados categóricos como entrada.
       </span>
      </span>
     </span>
     ; na
     <i>
      regressão simbólica
     </i>
     são fornecidas as variáveis numéricas de entrada e saída do problema, de forma que a saída do algoritmo é a expressão matemática que melhor descreve a relação entre os dados; o
     <i>
      agrupamento
     </i>
     visa identificar grupos nos dados contínuos fornecidos, devolvendo um rótulo discreto; nas
     <i>
      regras de associação
     </i>
     , pretende-se encontrar correlações entre grupos de objetos de entrada, que são dados não numéricos (
     <i>
      string
     </i>
     ou objetos); a
     <i>
      redução de dimensionalidade
     </i>
     visa diminuir a representação de um dado de entrada, de um número
     <i>
      N
     </i>
     de variáveis de entrada para um número
     <i>
      L
     </i>
     de variáveis de saída, onde
     <math display="inline">
      <mrow>
       <mi>
        L
       </mi>
       <mo>
        ≤
       </mo>
       <mi>
        N
       </mi>
      </mrow>
     </math>
     ; já os
     <i>
      autoencoders
     </i>
     convertem uma representação de entrada em uma nova representação de saída, com dimensionalidades iguais ou não.
    </p>
    <div class="row fig" id="S1_F3">
     <a name="S1_F3">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS1_F3" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/1914ec25310241a5a875df77c8b4ef3ad32d76d2.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figura 3
      </strong>
      <br/>
      Aprendizado de Máquina Supervisionado: (a) Dados em representação tabular, com destaque para uma separação arbitrária entre conjunto de treinamento (em verde) e teste (em amarelo); (b) Uso de algoritmo supervisionado onde primeiro são usados dados para o treinamento (em verde), seguido do uso do algoritmo treinado (em amarelo); (c) Resultado esquemático de uma regressão em uma dimensão (apenas uma
      <i>
       feature
      </i>
      denotada por
      <i>
       x
      </i>
      ), na qual é possível distinguir entre curvas treinadas com sub-ajuste, sobre-ajuste e ajuste aceitável.
      <br/>
     </div>
    </div>
    <p>
     Por fim, é realizada a etapa de análise de resultados representada na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F2" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      2
     </a>
     (a), na qual são usadas métricas de desempenho específicas para cada classe de algoritmo e tarefa realizada (também chamada de etapa de
     <i>
      teste
     </i>
     no caso supervisionado). Além de verificar se os algoritmos possuem desempenho satisfatório para a solução do problema, é nessa etapa que são feitas as interpretações de resultados, seja para a geração de conhecimento extraído com o auxilio dessas técnicas ou para a compreensão das decisões tomadas pelos algoritmos. É importante perceber que por serem algoritmos estatísticos, as soluções encontradas por métodos de aprendizado de máquina raramente possuem precisão de 100% (em geral, é uma boa prática duvidar de soluções com tais precisões por normalmente estarem associadas a erros de uso). Por isso tais técnicas são comumente usadas em cenários onde não se conhecem soluções exatas e as performances obtidas são comparadas as melhores soluções vigentes (chamadas de modelo base).
    </p>
    <p>
     A caraterística estatística desses algoritmos requer que os dados sejam exemplos de um mesmo problema. Matematicamente, podemos representar um exemplo ou instância por uma tupla
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mn>
         1
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mn>
         2
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <mi mathvariant="normal">
        …
       </mi>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mi>
         n
        </mi>
       </msub>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         y
        </mi>
        <mn>
         1
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         y
        </mi>
        <mn>
         2
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <mrow>
        <mi mathvariant="normal">
         …
        </mi>
        <mo>
         ⁢
        </mo>
        <msub>
         <mi>
          y
         </mi>
         <mi>
          m
         </mi>
        </msub>
       </mrow>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     , onde as variáveis denotadas por
     <i>
      x
     </i>
     representam informações sobre o problema (em inglês,
     <i>
      features
     </i>
     ) e as variáveis denotadas por
     <i>
      y
     </i>
     representam soluções observadas (saídas). Neste caso, a instância tem
     <i>
      n
     </i>
     entradas e
     <i>
      m
     </i>
     saídas. Podemos simplificar nossa abordagem para os problemas que apresentam uma única saída, isto é,
     <math display="inline">
      <mrow>
       <mo stretchy="false">
        (
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mn>
         1
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mn>
         2
        </mn>
       </msub>
       <mo>
        ,
       </mo>
       <mi mathvariant="normal">
        …
       </mi>
       <mo>
        ,
       </mo>
       <msub>
        <mi>
         x
        </mi>
        <mi>
         n
        </mi>
       </msub>
       <mo>
        ,
       </mo>
       <mi>
        y
       </mi>
       <mo stretchy="false">
        )
       </mo>
      </mrow>
     </math>
     . Além disso, cada tupla é apenas uma instância de um problema sobre o qual observamos
     <i>
      k
     </i>
     exemplos, que podemos estruturar na forma de uma tabela com
     <i>
      k
     </i>
     linhas, ilustrada na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F3" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      3
     </a>
     (a).
    </p>
    <p>
     Assumindo que estabelecemos nossa representação tabular por
     <i>
      k
     </i>
     tuplas, na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F3" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      3
     </a>
     (b) apresentamos um esquema de uso de algoritmos supervisionados. A caixa denotada por
     <i>
      IA
     </i>
     representa um algoritmo de aprendizado de máquina que possui parâmetros internos de funcionamento (hiperparâmetros). Esse algoritmo de IA recebe dados de entrada e gera dados de saída, a princípio, como uma caixa-preta. O uso do algoritmo se dá em duas etapas: na primeira etapa, denominada etapa de treinamento, são fornecidos exemplos de um problema que se quer modelar; na segunda etapa, denominada de teste, o algoritmo treinado é testado e seu desempenho é comparado com o modelo base e o desempenho de outros algoritmos para a mesma tarefa.
    </p>
    <p>
     Para realizar o treinamento, selecionamos um conjunto de exemplos da nossa tabela de observações e fornecemos para o algoritmo os pares entrada/saída. Cada algoritmo de aprendizado supervisionado utilizará uma tática diferente, que em linhas gerais, envolve um aprendizado estatístico de minimização de uma função custo (
     <i>
      loss function
     </i>
     ) que calcula a diferença entre o valor estimado
     <i>
      y
      <sub>
       pred
      </sub>
     </i>
     (usando as entradas
     <i>
      X
      <sub>
       train
      </sub>
     </i>
     ) e as saídas fornecidas
     <i>
      y
      <sub>
       train
      </sub>
     </i>
     . Uma vez que a otimização da função custo se encerra sobre os exemplos de treinamento fornecidos, o algoritmo está pronto para ser usado como um modelo preditivo.
    </p>
    <p>
     Uma questão importante que surge é se o algoritmo tem generalidade suficiente para encontrar uma resposta plausível para novos dados de entrada, quando dados de treinamento e teste são amostras da mesma região do espaço do problema. Para testar isso, uma parte das observações que não foram usadas para treinamento são usadas agora na etapa de teste. Cada saída do algoritmo
     <i>
      y
      <sub>
       pred
      </sub>
     </i>
     (usando as entradas
     <i>
      X
      <sub>
       test
      </sub>
     </i>
     ) é comparada com a resposta verdadeiramente observada
     <i>
      y
      <sub>
       true
      </sub>
     </i>
     . Essas comparações são feitas usando métricas estabelecidas para cada tipo de tarefa e representam a qualidade final do algoritmo em solucionar o problema proposto. É importante notar que, caso sejam usados os mesmos dados de treinamento e teste, então o algoritmo apenas irá gerar a saída já observada (e otimizada na etapa de treino). Este problema é um tipo de sobre-ajuste (
     <i>
      overfitting
     </i>
     ), quando observamos um bom desempenho do algoritmo apenas sobre o mesmo conjunto de dados usado no treinamento, e um desempenho ruim quando são fornecidos exemplos novos. Diz-se que o modelo treinado não tem capacidade de generalização por ter aprendido a variância contida em um único conjunto de dados. O
     <i>
      overfitting
     </i>
     também pode ocorrer quando o modelo é demasiado complexo, capturando todos as nuances dos dados, como quando usamos uma função polinomial de grau elevado para realizar o ajuste (
     <i>
      fitting
     </i>
     ) dos dados.
    </p>
    <p>
     Outro problema que pode ocorrer é o sub-ajuste (
     <i>
      underfitting
     </i>
     ). Neste caso o modelo é incapaz de capturar o padrão dos dados. Isto pode ocorrer pois o modelo é demasiado simples (por exemplo, uma função linear para descrever dados não lineares), ou porque não foram fornecidos dados suficientes para o modelo.
    </p>
    <p>
     Esses dois problemas (
     <i>
      overfitting
     </i>
     e
     <i>
      underfitting
     </i>
     ) são ilustrados esquematicamente na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F3" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      3
     </a>
     (c). Em linhas gerais, ambos os problemas estão relacionados a complexidade do modelo (se elevada ou simplificada demais) e a estatística dos dados usados (espaço amostrado pelos exemplos fornecidos – caraterizado pela quantidade, dimensionalidade, qualidade e relação das amostras). Assim, a divisão treino/teste é uma metodologia padrão para evitar tais problemas no aprendizado de máquina supervisionado.
    </p>
    <p>
     Somado a esses problemas, outra questão importante a ser discutida sobre os modelos de IA é seu tratamento como caixa-preta. Neste sentido, o modelo não explica como chegou nas conclusões apresentadas, sejam elas descritivas ou preditivas. Pelo fato desses algoritmos de aprendizado serem agnósticos ao domínio do problema, mapeando um problema específico fornecido em um problema de otimização, o modelo não elabora passos de análise e síntese que físicos e outros profissionais estão habituados. Por isso, ao analisar os resultados obtidos, percebemos em geral, que o modelo funciona apenas como uma caixa que dada uma entrada, reproduz o padrão esperado da saída. Isso pode gerar uma baixa confiança no modelo [
     <span class="ref">
      <sup class="xref xrefblue">
       19
      </sup>
      <span class="refCtt closed">
       <span>
        [19] M. Franklin e D. Lagnado, em: HCI International 2022 Posters, editado por StephanidisC., M. Antona e S. Ntoa (Springer, Cham, 2022).
       </span>
      </span>
     </span>
     ]. Caso haja um modelo teórico já estabelecido e acurado, a utilidade de um modelo de aprendizado de máquina no formato caixa-preta faz sentido quando possui uma acurácia igual ou superior e um custo computacional (de tempo e/ou recursos) menor. Este tipo de modelo também é chamado de modelo substituto (
     <i>
      surrogate model
     </i>
     ) e sua utilidade reside em reduzir custo de processamento com relação ao modelo base teórico. Por outro lado, novas técnicas tem sido pesquisadas para tornar as caixas-pretas mais transparentes, em um esforço de criar modelos de inteligência artificial explicáveis (conhecidos sob a sigla XAI,
     <i>
      Explainable AI
     </i>
     [
     <span class="ref">
      <sup class="xref xrefblue">
       20
      </sup>
      <span class="refCtt closed">
       <span>
        [20] M. Popolin Neto e F.V. Paulovich, IEEE Trans. Vis. Comput. Graph. 27, 1427 (2021).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       21
      </sup>
      <span class="refCtt closed">
       <span>
        [21] P.A. Angelov, E.A. Soares, R. Jiang, N.I. Arnold e P.M. Atkinson, WIREs Data Mining and Knowledge Discovery 11, e1424 (2021).
       </span>
      </span>
     </span>
     ]). Modelos de regressão simbólica que encontram as expressões matemáticas que relacionam a entrada com a saída são um exemplo de modelos explicáveis [
     <span class="ref">
      <sup class="xref xrefblue">
       22
      </sup>
      <span class="refCtt closed">
       <span>
        [22] S.M. Udrescu e M. Tegmark, Science Advances 6, eaay2631 (2020).
       </span>
      </span>
     </span>
     ], que inclusive são facilmente interpretáveis por físicos.
    </p>
    <p>
     Outras iniciativas visam diminuir a quantidade de dados (instâncias) necessária para se obter bons desempenhos com os algoritmos, na linha denominada
     <i>
      Zero-shot Learning
     </i>
     , [
     <span class="ref">
      <sup class="xref xrefblue">
       23
      </sup>
      <span class="refCtt closed">
       <span>
        [23] I. Sucholutsky e Schonlau M., Proceedings of the AAAI Conference on Artificial Intelligence 35, 9739 (2021).
       </span>
      </span>
     </span>
     ], ou utilizar modelos treinados com dados de um domínio em outros domínios relacionados, linha denominada de
     <i>
      Transfer Learning
     </i>
     [
     <span class="ref">
      <sup class="xref xrefblue">
       24
      </sup>
      <span class="refCtt closed">
       <span>
        [24] L. A. Torrey e J. Shavlik, em: Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods and Techniques, editado por SoriaE., MartinJ., MagdalenaR., M. Martinez e A. Serrano (IGI Global, Hershey, 2009), v. 1.
       </span>
      </span>
     </span>
     ].
    </p>
    <p>
     A área de aprendizado de máquina é muito ampla e ativa, com novos desenvolvimentos aparecendo constantemente na literatura. Não é objetivo deste trabalho descrever em detalhes todas as suas nuances. Para uma discussão mais aprofundada, recomendamos a leitura da literatura base já bem estabelecida [
     <span class="ref">
      <sup class="xref xrefblue">
       16
      </sup>
      <span class="refCtt closed">
       <span>
        [16] K. Faceli, A.C. Lorena, J. Gama, T.A. Almeida e L.F.A.C.P.Carvalho, Inteligência Artificial – Uma Abordagem de Aprendizado de Máquina (LTC, Rio de Janeiro, 2021).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       17
      </sup>
      <span class="refCtt closed">
       <span>
        [17] A. Géron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow (O’Reilly Media, Sebastopol, 2019), 2 ed.
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       18
      </sup>
      <span class="refCtt closed">
       <span>
        [18] A. Burkov, Machine learning engineering (True Positive, Quebec, 2020).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       25
      </sup>
      <span class="refCtt closed">
       <span>
        [25] M. Kubat, An introduction tomachine learning (Springer International Publishing, Basel, 2015), 1 ed.
       </span>
      </span>
     </span>
     ]. Para uma introdução ao
     <i>
      Aprendizado Profundo
     </i>
     no qual são usados algoritmos de redes neurais artificiais, sugerimos o trabalho de Arruda et al. [
     <span class="ref">
      <sup class="xref xrefblue">
       26
      </sup>
      <span class="refCtt closed">
       <span>
        [26] H.F. Arruda, A. Benatti, C.H. Comin e L.F. Costa, Revista Brasileira de Ensino de Física 44, e20220101 (2022).
       </span>
      </span>
     </span>
     ].
    </p>
    <div class="row fig" id="S1_F4">
     <a name="S1_F4">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS1_F4" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/8d46f9465aa0dce7119053a82a96860afd608463.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figure 4
      </strong>
      <br/>
      Aparatos experimentais utilizados: (a) para os ângulos de
      <math display="inline">
       <msup>
        <mn>
         5
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      ,
      <math display="inline">
       <msup>
        <mn>
         10
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      ,
      <math display="inline">
       <msup>
        <mn>
         15
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      e
      <math display="inline">
       <msup>
        <mn>
         20
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      com esfera, disco e aro de aço; (b) para os ângulos de
      <math display="inline">
       <msup>
        <mn>
         4
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      e
      <math display="inline">
       <msup>
        <mn>
         7.7
        </mn>
        <mo>
         ∘
        </mo>
       </msup>
      </math>
      com aro de PVC e esfera de vidro.
      <br/>
     </div>
    </div>
    <h1 class="articleSectionTitle">
     Metodologia
    </h1>
    <h2>
     2.1. Experimental
    </h2>
    <p>
     A obtenção dos dados de rolagem de diferentes objetos foi feita usando dois planos inclinados apresentados na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F4" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      4
     </a>
     . O plano inclinado em (a) é adaptado de um kit didático com sensores eletrônicos e controle preciso de angulação, e as medidas foram feitas dentro de um laboratório didático da Universidade Federal do Oeste da Bahia. Já o plano inclinado mostrado em (b) foi construído com materiais de fácil acesso a qualquer estudante, sendo que os dados foram coletados com auxílio de um cronômetro de um telefone celular disparado manualmente e foram realizadas na residência do primeiro autor deste trabalho (HF). Em cada aparato foram feitas marcações de largada e chegada. Os objetos foram soltos do repouso a partir de uma linha de largada, momento em que se inicia a contagem de tempo, que é medido até o objeto cruzar a linha de chegada. Foram realizadas, para cada altura inicial, cerca de dez repetições para cada objeto. Os objetos utilizados foram: aro, cilindro (disco) e esfera de materiais diferentes como se observa na Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F4" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      4
     </a>
     .
    </p>
    <p>
     Uma característica dos métodos de aprendizado de máquina é que eles são adaptativos: quanto mais dados disponíveis, mais precisos eles tendem a ser. Desta forma, neste experimento coletamos uma grande quantidade de dados, cerca de 800 medições, que são disponibilizados no material suplementar.
    </p>
    <h2>
     2.2. Computacional
    </h2>
    <p>
     Neste trabalho realizamos as tarefas de classificação e regressão para demonstrar o uso do Aprendizado de Máquina no problema do plano inclinado. Inicialmente foram selecionadas as variáveis descritivas (
     <i>
      features
     </i>
     ) que representam cada exemplo dos dados para cada tarefa. Para a classificação, foi considerada a tupla (altura, ângulo, tempo) como entrada
     <i>
      X
     </i>
     e o objeto (aro, cilindro ou esfera) como saída
     <i>
      y
     </i>
     . Isso significa que desejamos descobrir o objeto nos baseando somente na medida da altura, do ângulo e do tempo que o objeto demora para percorrer o percurso. Para a regressão, foi considerada a tupla (altura, ângulo, classe 1, classe 2, classe 3) como entrada
     <i>
      X
     </i>
     e a velocidade média como saída
     <i>
      y
     </i>
     . A utilização de três novas colunas para representar cada classe é denominada
     <i>
      one-hot encoding
     </i>
     , uma vez que entradas de algoritmos de aprendizado de máquina devem ser números (palavras aro, cilindro e esfera não podem ser inseridas diretamente). O
     <i>
      one-hot encoding
     </i>
     transforma cada palavra da coluna de objeto inicial em uma nova coluna, colocando o número 1 quando a respectiva linha for do objeto denotado naquela coluna e 0 quando não for.
    </p>
    <p>
     Todas as
     <i>
      features
     </i>
     foram escalonadas através da técnica
     <i>
      MinMaxScaler
     </i>
     que consiste em transformar cada coluna para que os valores fiquem no intervalo de 0 a 1. Isso é necessário para que todas as
     <i>
      features
     </i>
     sejam consideradas de maneira igual no funcionamento interno de alguns algoritmos de aprendizado de máquina. O escalonamento do k-ésimo elemento da i-ésima coluna é escrito como:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS2_E14">
     <a name="S2_E14">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (14)
       </span>
       <math display="block">
        <mrow>
         <mrow>
          <msubsup>
           <mi>
            x
           </mi>
           <mrow>
            <mi>
             k
            </mi>
            <mo>
             ⁢
            </mo>
            <mi>
             i
            </mi>
           </mrow>
           <mo>
            ′
           </mo>
          </msubsup>
          <mo>
           =
          </mo>
          <mfrac>
           <mrow>
            <msub>
             <mi>
              x
             </mi>
             <mrow>
              <mi>
               k
              </mi>
              <mo>
               ⁢
              </mo>
              <mi>
               i
              </mi>
             </mrow>
            </msub>
            <mo>
             -
            </mo>
            <mrow>
             <mi>
              m
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              i
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              n
             </mi>
             <mo>
              ⁢
             </mo>
             <mrow>
              <mo stretchy="false">
               (
              </mo>
              <msub>
               <mi>
                x
               </mi>
               <mi>
                i
               </mi>
              </msub>
              <mo stretchy="false">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
           <mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              a
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              x
             </mi>
             <mo>
              ⁢
             </mo>
             <mrow>
              <mo stretchy="false">
               (
              </mo>
              <msub>
               <mi>
                x
               </mi>
               <mi>
                i
               </mi>
              </msub>
              <mo stretchy="false">
               )
              </mo>
             </mrow>
            </mrow>
            <mo>
             -
            </mo>
            <mrow>
             <mi>
              m
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              i
             </mi>
             <mo>
              ⁢
             </mo>
             <mi>
              n
             </mi>
             <mo>
              ⁢
             </mo>
             <mrow>
              <mo stretchy="false">
               (
              </mo>
              <msub>
               <mi>
                x
               </mi>
               <mi>
                i
               </mi>
              </msub>
              <mo stretchy="false">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mfrac>
         </mrow>
         <mo>
          .
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     Foram utilizadas a biblioteca de Aprendizado de Máquina de código aberto Scikit-Learn [
     <span class="ref">
      <sup class="xref xrefblue">
       27
      </sup>
      <span class="refCtt closed">
       <span>
        [27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., Journal of Machine Learning Research 12, 2825 (2011).
       </span>
      </span>
     </span>
     ] na versão 0.24.2 e a linguagem de programação Python [
     <span class="ref">
      <sup class="xref xrefblue">
       28
      </sup>
      <span class="refCtt closed">
       <span>
        [28] G. van Rossum, Python tutorial. Technical Report CS-R9526 (Centrum voor Wiskunde en Informatica, Amsterdam, 1995).
       </span>
      </span>
     </span>
     ] na versão 3.9.5. O código desenvolvido está disponível como um Jupyter Notebook no material suplementar deste artigo (
     <a href="https://github.com/simcomat/IArpi" target="_blank">
      https://github.com/simcomat/IArpi
     </a>
     ). Isso permite que o leitor reproduza os resultados e faça as análises que considerar conveniente.
    </p>
    <p>
     Para a classificação considerou-se dez algoritmos diferentes, sendo oito deles de aprendizado de máquina, um denotado de modelo base (BM) e outro construído através do modelo físico da Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E5" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      5
     </a>
     . O modelo BM é um comparativo com a probabilidade de aleatoriamente rotular cada entrada (altura, ângulo, tempo) com uma classe (aro, cilindro ou esfera) equiprovável. Neste caso, o BM é usado como valor mínimo de comparação, uma vez que qualquer método de classificação diferente do puro acaso deve possuir índices de performance superiores a ele em dados balanceados (aproximadamente a mesma quantidade de exemplos para cada classe). Os classificadores LDA (Linear Discriminant Analysis), QDA (Quadratic Discriminant Analysis) e GNB (Guassian Naive Bayes) são algoritmos de aprendizado de máquina baseados em modelos probabilísticos. Os classificadores RF (Random Forest) e GD (Gradient Boosting) são algoritmos de ensemble de Árvores de Decisão. O algoritmo MLP (Multilayer Percepetron) é baseado em redes neurais. Já o KNN (K-Vizinhos Mais Próximos) e o SVM (Máquina de Vetor Suporte) são métodos baseados na proximidade espacial dos dados em
     <i>
      N
     </i>
     dimensões. Uma discussão detalhada sobre o funcionamento interno de cada um desses algoritmos pode ser encontrada na literatura especializada [
     <span class="ref">
      <sup class="xref xrefblue">
       16
      </sup>
      <span class="refCtt closed">
       <span>
        [16] K. Faceli, A.C. Lorena, J. Gama, T.A. Almeida e L.F.A.C.P.Carvalho, Inteligência Artificial – Uma Abordagem de Aprendizado de Máquina (LTC, Rio de Janeiro, 2021).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       17
      </sup>
      <span class="refCtt closed">
       <span>
        [17] A. Géron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow (O’Reilly Media, Sebastopol, 2019), 2 ed.
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       18
      </sup>
      <span class="refCtt closed">
       <span>
        [18] A. Burkov, Machine learning engineering (True Positive, Quebec, 2020).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       25
      </sup>
      <span class="refCtt closed">
       <span>
        [25] M. Kubat, An introduction tomachine learning (Springer International Publishing, Basel, 2015), 1 ed.
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       27
      </sup>
      <span class="refCtt closed">
       <span>
        [27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., Journal of Machine Learning Research 12, 2825 (2011).
       </span>
      </span>
     </span>
     ]. Como exemplo, apresentamos as principais ideias do KNN no Apêndice C.
    </p>
    <div class="row fig" id="S2_F5">
     <a name="S2_F5">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS2_F5" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/56b9611025edae2a6d1f6979459de3b270c86ae4.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figure 5
      </strong>
      <br/>
      Gráficos de dispersão dos dados medidos: (a), (b) e (c) são a dispersão do tempo em função da altura inicial para esfera, cilindro e aro, respectivamente; (d), (e) e (f) são a dispersão da velocidade média em função da altura inicial para esfera, cilindro e aro, respectivamente.
      <br/>
     </div>
    </div>
    <div class="row fig" id="S2_F6">
     <a name="S2_F6">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS2_F6" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/275b5bad3d0efe6b8c44b375f6d6ff2fbf40405b.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figure 6
      </strong>
      <br/>
      Resultados da Avaliação de Desempenho da Classificação para o conjunto de teste
      <i>
       x
       <sub>
        test
       </sub>
      </i>
      : (a) Acurácia e (b) Coeficiente
      <math display="inline">
       <mi>
        κ
       </mi>
      </math>
      de Cohen para os algoritmos de classificação usados; (c) Matriz de Confusão para o algoritmo KNN; (d) Distribuição dos coeficientes
      <math display="inline">
       <mi>
        β
       </mi>
      </math>
      preditos pelo modelo físico para os dados de teste (em tracejado estão o valores esperados pela teoria).
      <br/>
     </div>
    </div>
    <div class="row fig" id="S2_F7">
     <a name="S2_F7">
     </a>
     <div class="col-md-4 col-sm-4">
      <a data-target="#ModalFigS2_F7" data-toggle="modal" href="">
       <div class="thumbImg">
        <img src="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/7743c38371614dccf0035d6749930a089d377196.jpg"/>
        <div class="zoom">
         <span class="sci-ico-zoom">
         </span>
        </div>
       </div>
      </a>
     </div>
     <div class="col-md-8 col-sm-8">
      <strong>
       Figure 7
      </strong>
      <br/>
      Resultados da Avaliação de Desempenho da Regressão para o conjunto de teste
      <i>
       x
       <sub>
        test
       </sub>
      </i>
      : (a) Erro Absoluto Médio, MAE; (b) Coeficiente de Determinação
      <math display="inline">
       <msup>
        <mi>
         R
        </mi>
        <mn>
         2
        </mn>
       </msup>
      </math>
      para os algoritmos de regressão usados; Dispersão da velocidade média predita
      <i>
       y
       <sub>
        pred
       </sub>
      </i>
      pelo em função da velocidade média experimental
      <i>
       y
       <sub>
        true
       </sub>
      </i>
      para o KNNR (c) e para o modelo físico (d).
      <br/>
     </div>
    </div>
    <p>
     Como métrica de desempenho da classificação foram usadas a acurácia e o coeficiente
     <math display="inline">
      <mi>
       κ
      </mi>
     </math>
     de Cohen. A acurácia mede o total de exemplos corretamente classificados pelo total de exemplos testados. Ela pode ser calculada através da matriz de confusão, uma representação gráfica onde as linhas
     <i>
      i
     </i>
     representam as classes verdadeiras dos dados e as colunas
     <i>
      j
     </i>
     as classes preditas (cada valor
     <i>
      e
      <sub>
       ij
      </sub>
     </i>
     da matriz é o total de exemplos da classe
     <i>
      i
     </i>
     predito para a classe
     <i>
      j
     </i>
     , sendo o total de acertos quando
     <i>
      i=j
     </i>
     e de erros quando
     <math display="inline">
      <mrow>
       <mi>
        i
       </mi>
       <mo>
        ≠
       </mo>
       <mi>
        j
       </mi>
      </mrow>
     </math>
     ). Já o coeficiente
     <math display="inline">
      <mi>
       κ
      </mi>
     </math>
     de Cohen mede o quanto o classificador difere de um classificador que apenas sorteia a classe predita, onde
     <math display="inline">
      <mrow>
       <mrow>
        <mo>
         -
        </mo>
        <mn>
         1
        </mn>
       </mrow>
       <mo>
        ≤
       </mo>
       <mi>
        κ
       </mi>
       <mo>
        ≤
       </mo>
       <mn>
        1
       </mn>
      </mrow>
     </math>
     , sendo valores abaixo de 0.2 considerados próximos ao classificador aleatório. Para valores próximos de 1 o classificador está predizendo exatamente os valores esperados (i.e.,
     <math display="inline">
      <mrow>
       <msub>
        <mi>
         y
        </mi>
        <mrow>
         <mi>
          p
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          r
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          e
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          d
         </mi>
        </mrow>
       </msub>
       <mo>
        =
       </mo>
       <msub>
        <mi>
         y
        </mi>
        <mrow>
         <mi>
          t
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          r
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          u
         </mi>
         <mo>
          ⁢
         </mo>
         <mi>
          e
         </mi>
        </mrow>
       </msub>
      </mrow>
     </math>
     ) [
     <span class="ref">
      <sup class="xref xrefblue">
       29
      </sup>
      <span class="refCtt closed">
       <span>
        [29] J. Cohen, Educational and Psychological Measurement 20, 37 (1960).
       </span>
      </span>
     </span>
     ].
    </p>
    <p>
     Para a regressão foram escolhidos sete algoritmos diferentes, sendo seis deles de aprendizado de máquina e um o modelo físico (MF). Para o aprendizado de máquina foram escolhidas as contrapartes de regressão da Máquina de Vetor Suporte (SVMR), do K-Vizinhos Mais Próximos (KNNR), da Random Forest (RFR), do Gradient Boosting (GBR) e do Multilayer Perceptron (MLPR). Além destes, foi feita a regressão linear tradicional (LR) que realiza a minimização dos quadrados dos resíduos para obter os melhores coeficientes de uma combinação linear das
     <i>
      features
     </i>
     de entrada.
    </p>
    <p>
     Como métrica de desempenho da regressão foram usados o coeficiente de determinação
     <math display="inline">
      <msup>
       <mi>
        R
       </mi>
       <mn>
        2
       </mn>
      </msup>
     </math>
     e o erro absoluto médio (MAE), conforme implementados no Scikit-Learn [
     <span class="ref">
      <sup class="xref xrefblue">
       27
      </sup>
      <span class="refCtt closed">
       <span>
        [27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., Journal of Machine Learning Research 12, 2825 (2011).
       </span>
      </span>
     </span>
     ]:
    </p>
    <p>
    </p>
    <div class="row formula" id="eS2_E15">
     <a name="S2_E15">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (15)
       </span>
       <math display="block">
        <mrow>
         <msup>
          <mi>
           R
          </mi>
          <mn>
           2
          </mn>
         </msup>
         <mo>
          =
         </mo>
         <mn>
          1
         </mn>
         <mo>
          −
         </mo>
         <mfrac>
          <mrow>
           <mstyle displaystyle="true">
            <msubsup>
             <mo>
              ∑
             </mo>
             <mrow>
              <mi>
               j
              </mi>
              <mo>
               =
              </mo>
              <mn>
               1
              </mn>
             </mrow>
             <mrow>
              <msub>
               <mi>
                k
               </mi>
               <mrow>
                <mi>
                 t
                </mi>
                <mi>
                 e
                </mi>
                <mi>
                 s
                </mi>
                <mi>
                 t
                </mi>
               </mrow>
              </msub>
             </mrow>
            </msubsup>
            <mrow>
             <msup>
              <mrow>
               <mo stretchy="false">
                (
               </mo>
               <msub>
                <mi>
                 y
                </mi>
                <mrow>
                 <mi>
                  t
                 </mi>
                 <mi>
                  r
                 </mi>
                 <mi>
                  u
                 </mi>
                 <msub>
                  <mi>
                   e
                  </mi>
                  <mi>
                   j
                  </mi>
                 </msub>
                </mrow>
               </msub>
               <mo>
                −
               </mo>
               <msub>
                <mi>
                 y
                </mi>
                <mrow>
                 <mi>
                  p
                 </mi>
                 <mi>
                  r
                 </mi>
                 <mi>
                  e
                 </mi>
                 <msub>
                  <mi>
                   d
                  </mi>
                  <mi>
                   j
                  </mi>
                 </msub>
                </mrow>
               </msub>
               <mo stretchy="false">
                )
               </mo>
              </mrow>
              <mn>
               2
              </mn>
             </msup>
            </mrow>
           </mstyle>
          </mrow>
          <mrow>
           <mstyle displaystyle="true">
            <msubsup>
             <mo>
              ∑
             </mo>
             <mrow>
              <mi>
               j
              </mi>
              <mo>
               =
              </mo>
              <mn>
               1
              </mn>
             </mrow>
             <mrow>
              <msub>
               <mi>
                k
               </mi>
               <mrow>
                <mi>
                 t
                </mi>
                <mi>
                 e
                </mi>
                <mi>
                 s
                </mi>
                <mi>
                 t
                </mi>
               </mrow>
              </msub>
             </mrow>
            </msubsup>
            <mrow>
             <msup>
              <mrow>
               <mo stretchy="false">
                (
               </mo>
               <msub>
                <mi>
                 y
                </mi>
                <mrow>
                 <mi>
                  p
                 </mi>
                 <mi>
                  r
                 </mi>
                 <mi>
                  e
                 </mi>
                 <msub>
                  <mi>
                   d
                  </mi>
                  <mi>
                   j
                  </mi>
                 </msub>
                </mrow>
               </msub>
               <mo>
                −
               </mo>
               <msub>
                <mover accent="true">
                 <mi>
                  y
                 </mi>
                 <mo>
                  ¯
                 </mo>
                </mover>
                <mrow>
                 <mi>
                  t
                 </mi>
                 <mi>
                  r
                 </mi>
                 <mi>
                  u
                 </mi>
                 <msub>
                  <mi>
                   e
                  </mi>
                  <mi>
                   j
                  </mi>
                 </msub>
                </mrow>
               </msub>
               <mo stretchy="false">
                )
               </mo>
              </mrow>
              <mn>
               2
              </mn>
             </msup>
            </mrow>
           </mstyle>
          </mrow>
         </mfrac>
         <mo>
          ,
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <div class="row formula" id="eS2_E16">
     <a name="S2_E16">
     </a>
     <div class="col-md-12">
      <div class="formula-container">
       <span class="label">
        (16)
       </span>
       <math display="block">
        <mrow>
         <mi>
          M
         </mi>
         <mi>
          A
         </mi>
         <mi>
          E
         </mi>
         <mo>
          =
         </mo>
         <mfrac>
          <mn>
           1
          </mn>
          <mrow>
           <msub>
            <mi>
             k
            </mi>
            <mrow>
             <mi>
              t
             </mi>
             <mi>
              e
             </mi>
             <mi>
              s
             </mi>
             <mi>
              t
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mfrac>
         <mo>
          −
         </mo>
         <mstyle displaystyle="true">
          <munderover>
           <mo>
            ∑
           </mo>
           <mrow>
            <mi>
             j
            </mi>
            <mo>
             =
            </mo>
            <mn>
             1
            </mn>
           </mrow>
           <mrow>
            <msub>
             <mi>
              k
             </mi>
             <mrow>
              <mi>
               t
              </mi>
              <mi>
               e
              </mi>
              <mi>
               s
              </mi>
              <mi>
               t
              </mi>
             </mrow>
            </msub>
           </mrow>
          </munderover>
          <mrow>
           <mo>
            |
           </mo>
           <msub>
            <mi>
             y
            </mi>
            <mrow>
             <mi>
              t
             </mi>
             <mi>
              r
             </mi>
             <mi>
              u
             </mi>
             <msub>
              <mi>
               e
              </mi>
              <mi>
               j
              </mi>
             </msub>
            </mrow>
           </msub>
           <mo>
            −
           </mo>
           <msub>
            <mi>
             y
            </mi>
            <mrow>
             <mi>
              p
             </mi>
             <mi>
              r
             </mi>
             <mi>
              e
             </mi>
             <msub>
              <mi>
               d
              </mi>
              <mi>
               j
              </mi>
             </msub>
            </mrow>
           </msub>
           <mo>
            |
           </mo>
          </mrow>
         </mstyle>
         <mo>
          ,
         </mo>
        </mrow>
       </math>
      </div>
     </div>
    </div>
    <p>
     onde
     <i>
      k
      <sub>
       test
      </sub>
     </i>
     é a quantidade de exemplos no conjunto de teste e
     <math display="inline">
      <msub>
       <mover accent="true">
        <mi>
         y
        </mi>
        <mo stretchy="false">
         ¯
        </mo>
       </mover>
       <mrow>
        <mi>
         t
        </mi>
        <mo>
         ⁢
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ⁢
        </mo>
        <mi>
         u
        </mi>
        <mo>
         ⁢
        </mo>
        <mi>
         e
        </mi>
       </mrow>
      </msub>
     </math>
     a média aritmética de
     <i>
      y
      <sub>
       true
      </sub>
     </i>
     .
    </p>
    <p>
     Não foi feita a otimização dos hiperparâmetros de nenhum dos algoritmos utilizados, ou seja, todos os hiperparâmetros, tanto para a regressão quanto para a classificação, foram mantidos como padrão (
     <i>
      default
     </i>
     ) da implementação dos algoritmos no Scikit-Learn [
     <span class="ref">
      <sup class="xref xrefblue">
       27
      </sup>
      <span class="refCtt closed">
       <span>
        [27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., Journal of Machine Learning Research 12, 2825 (2011).
       </span>
      </span>
     </span>
     ].
    </p>
    <p>
     Para cada uma das tarefas, foram usados 80% dos dados como treinamento do modelo e 20% como teste. Cada exemplo foi escolhido aleatoriamente para pertencer a cada um desses dois conjuntos, sendo usado o
     <i>
      random state
     </i>
     de 42 (semente da função pseudoaleatória usada para inicializar a sequência).
    </p>
    <h1 class="articleSectionTitle">
     3. Resultados
    </h1>
    <p>
     Na Figura
     <a class="open-asset-modal" data-target="#ModalFigS2_F5" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      5
     </a>
     (a), (b) e (c) são apresentados os
     <i>
      k=803
     </i>
     dados coletados para a esfera (321), o cilindro (160) e o aro (322), respectivamente. Observa-se que os dados coletados pelo aparato experimental da Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F4" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      4
     </a>
     (b) (ângulos
     <math display="inline">
      <mn>
       4.0
      </mn>
     </math>
     e
     <math display="inline">
      <mn>
       7.7
      </mn>
     </math>
     ) possuem maior dispersão (menor precisão) do que aqueles medidos com o aparato (a), devido a imprecisões de construção e ao tempo de reação humano na medição. Apesar disso, ambos os resultados concordam com as tendências de quanto maior o ângulo de inclinação do plano, menor o tempo transcorrido; e que, para os mesmos ângulos e alturas, o tempo de descida do aro é maior do que do cilindro, que por sua vez, é maior do que da esfera.
    </p>
    <p>
     A velocidade média apresentada na Fig.
     <a class="open-asset-modal" data-target="#ModalFigS2_F5" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      5
     </a>
     (d), (e) e (f) foi calculada considerando-se a distância percorrida sobre o plano inclinado para o respectivo intervalo de tempo. Dessa forma, observa-se a propensão dos dados para uma linha de tendência geral para cada objeto, cujo tempo transcorrido é proporcional a raiz quadrada da altura inicial. Apesar da dispersão dos dados, é possível identificar a tendência de diminuição da velocidade média indo da esfera para o aro.
    </p>
    <p>
     Essa descrição analítica dos resultados pode ser usada para gerar modelos fenomenológicos da relação entre as variáveis através de uma abordagem física tradicional. A abordagem que focamos aqui é a construção de um modelo fenomenológico através dos algoritmos de aprendizado de máquina supervisionados, como descritos na Seção
     <strong>
      2.2
     </strong>
     .
    </p>
    <p>
     Uma vez estabelecidas as tarefas e as
     <i>
      features
     </i>
     necessárias, cada algoritmo escolhido foi treinado e testado. Os resultados são apresentados nas Figuras
     <a class="open-asset-modal" data-target="#ModalFigS2_F6" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      6
     </a>
     e
     <a class="open-asset-modal" data-target="#ModalFigS2_F7" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      7
     </a>
     . O modelo que apresentou melhor desempenho da tarefa de classificação foi o KNN, como pode ser visto nas Figuras
     <a class="open-asset-modal" data-target="#ModalFigS2_F6" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      6
     </a>
     (a) e (b), conseguindo acertar qual objeto rolava sobre o plano em 83.2% dos casos, com maior coeficiente de Cohen,
     <math display="inline">
      <mrow>
       <mi>
        κ
       </mi>
       <mo>
        =
       </mo>
       <mn>
        0.739
       </mn>
      </mrow>
     </math>
     . Na Figura
     <a class="open-asset-modal" data-target="#ModalFigS2_F6" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      6
     </a>
     (c) é apresentada a matriz de confusão para esse algoritmo, onde podemos ver os acertos e erros para cada objeto. Observa-se que o aro foi o menos confundido com os outros objetos (7 erros em 65, 10.8%), seguido do cilindro (4 erros em 32, 12.5%) e da esfera (16 erros em 65, 24.6%) – esses valores são obtidos pelas somas nas linhas da matriz. Uma possível explicação para o aro ser o menos confundido é o fato do seu coeficiente
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     ser o mais distante dos outros objetos (a diferença é de 0.5 entre
     <i>
      β
      <sub>
       aro
      </sub>
     </i>
     e
     <i>
      β
      <sub>
       cilindro
      </sub>
     </i>
     e de 0.6 entre é
     <i>
      β
      <sub>
       aro
      </sub>
     </i>
     e
     <i>
      β
      <sub>
       esfera
      </sub>
     </i>
     , enquanto a diferença entre
     <i>
      β
      <sub>
       cilindro
      </sub>
     </i>
     e
     <i>
      β
      <sub>
       esfera
      </sub>
     </i>
     é de 0.1).
    </p>
    <p>
     Como o modelo físico não prevê discretização de classes, obtivemos através dele um coeficiente
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     contínuo associado ao momento de inércia de cada objeto. Assim, o gráfico da Figura
     <a class="open-asset-modal" data-target="#ModalFigS2_F6" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      6
     </a>
     (d) representa a distribuição dos valores de
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     para cada objeto verdadeiro, obtidos através da Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E5" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      5
     </a>
     . O gráfico em (d) funciona de maneira análoga à matriz de confusão em (c), sendo cada distribuição a classe real do objeto e cada pico de distribuição o valor mais provável de
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     predito (ou seja, a classe predita). Observa-se pela tendência central das distribuições que cada objeto possui um momento de inércia característico. Entretanto, não é possível afirmar exatamente qual é cada objeto uma vez que ocorre sobreposição entre as distribuições observadas. É evidente que o modelo físico proposto possui limitações inerentes às hipóteses de sua elaboração e as restrições impostas para a comparação com os métodos de aprendizado de máquina (ambas abordagens trabalham com o mesmo conjunto de dados e variáveis). Apesar disso, a finalidade do contraste entre ambas as técnicas é demonstrar que a máquina foi capaz de aprender a distinguir os objetos partindo da mesma informação física fornecida ao modelo físico (
     <i>
      features
     </i>
     de entrada). Uma limitação que surge deste contraste é que a máquina não estabelece que a propriedade que permite distinguir os objetos seja uma propriedade física dos objetos (o momento de inércia), se restringindo a reproduzir o padrão aprendido dos dados. Em outras palavras, embora a máquina tenha sido capaz de induzir a física que reproduz os dados ela não é capaz de deduzir as propriedades físicas que dão origem a esses padrões.
    </p>
    <p>
     Os modelos de regressão da Figura
     <a class="open-asset-modal" data-target="#ModalFigS2_F7" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      7
     </a>
     também demonstram que os algoritmos de aprendizado de máquina foram capazes de reproduzir o padrão dos dados. Pelo contraste do desempenho entre o modelo físico e o melhor modelo de aprendizado de máquina (KNNR), Figuras
     <a class="open-asset-modal" data-target="#ModalFigS2_F7" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      7
     </a>
     (b) e (c), observa-se que as limitações do modelo físico proposto trazem maior incerteza à predição da velocidade média de descida do objeto (erro médio de 0.055
     <math display="inline">
      <mrow>
       <mi class="ltx_unit" mathvariant="normal">
        m
       </mi>
       <mtext>
       </mtext>
       <msup>
        <mi class="ltx_unit" mathvariant="normal">
         s
        </mi>
        <mrow>
         <mo>
          -
         </mo>
         <mn>
          1
         </mn>
        </mrow>
       </msup>
      </mrow>
     </math>
     para o modelo físico e 0.014
     <math display="inline">
      <mrow>
       <mi class="ltx_unit" mathvariant="normal">
        m
       </mi>
       <mtext>
       </mtext>
       <msup>
        <mi class="ltx_unit" mathvariant="normal">
         s
        </mi>
        <mrow>
         <mo>
          -
         </mo>
         <mn>
          1
         </mn>
        </mrow>
       </msup>
      </mrow>
     </math>
     para o KNNR). A velocidade média predita pelo modelo físico é sempre menor que a velocidade experimental medida, o que novamente indica as limitações do modelo devido a inadequação das hipóteses assumidas de que o objeto rola sem deslizar ou que a velocidade inicial é nula. O modelo de aprendizado de máquina não se baseia nessas hipóteses do modelo físico, atendo-se a aprender o padrão dos dados, e conseguindo um desempenho melhor como modelo fenomenológico de predição.
    </p>
    <p>
     Um último detalhe que gostaríamos de destacar é que as
     <i>
      features
     </i>
     escolhidas para esse problema foram determinadas pelo conhecimento do domínio de física. Ou seja, apesar dos modelos de aprendizado de máquina não saberem física internamente, a física foi adicionada a eles pela escolha consciente dos dados de entrada (altura, ângulo e tempo). Por exemplo, se assumíssemos que a cor dos objetos fosse um atributo relevante, o modelo de aprendizado de máquina permitiria que essa informação fosse inserida. Se ainda, por descuido, escolhêssemos um objeto de cada cor, então a cor seria atributo suficiente para o modelo de aprendizado de máquina classificar corretamente os dados. Todavia, sabemos que a cor do objeto de nada importa neste problema. Para invalidarmos a escolha dessa
     <i>
      feature
     </i>
     precisaríamos aumentar a amostragem dos nossos dados, de forma a ter objetos iguais de cores diferentes. Só assim o modelo aprenderia estatisticamente que a cor não é relevante para o problema proposto. É a esse tipo de amostragem do espaço de dados que nos referimos ao destacar que o aprendizado de máquina requer dados em quantidade e qualidade suficiente para funcionar adequadamente. No problema aqui tratado, poderíamos adicionar informações da massa
     <i>
      m
     </i>
     e do raio
     <i>
      R
     </i>
     de cada objeto ou do atrito
     <math display="inline">
      <mi>
       μ
      </mi>
     </math>
     entre o objeto e o plano. Com essa informação adicional nos dados, é provável que a performance dos algoritmos fosse ainda melhor, o que não significa que o modelo aprendeu mais física com os dados, apenas que um conjunto maior de atributos permite distinguir melhor entre três objetos, já que a chance de um atributo ser diferente é maior. Contudo, precisaríamos garantir que houvesse repetições para objetos diferentes com a mesma massa ou o mesmo raio, para evitar que o modelo utilizasse essa informação como única suficiente para separar os dados. Esse desafio de amostragem dos dados está relacionado à
     <i>
      maldição da dimensionalidade
     </i>
     : quanto maior o espaço de entrada, mais dados são necessários para que tenhamos uma amostragem significativa o suficiente para que o modelo não fique enviesado para o subespaço amostrado pelos dados – o que pode facilmente ser impossibilitado pela explosão combinatória. Dessa forma, aqui tratamos apenas de um subespaço do problema geral do rolamento no plano inclinado. Se aumentarmos a mistura dos nossos experimentos para ter mais condições diferentes de atrito, o desempenho do algoritmo irá progressivamente diminuir, à medida que não possui
     <i>
      features
     </i>
     para “aprender” o atrito. Essa é uma sutileza que gostaríamos de enfatizar, observando que realizamos experimentos em duas condições de atrito diferentes (Figura
     <a class="open-asset-modal" data-target="#ModalFigS1_F4" data-toggle="modal" href="">
      <span class="sci-ico-fileFigure">
      </span>
      4
     </a>
     ), sem comprometer o desempenho, uma vez que os algoritmos aprendem a separação dos objetos pelos ângulos, facilitando a predição. Apesar do algoritmo se valer disso de maneira indireta, lembramos que a dispersão dos dados de
     <math display="inline">
      <mi>
       β
      </mi>
     </math>
     tem uma origem física, já que a medida à qual temos acesso experimental é de
     <math display="inline">
      <mi>
       γ
      </mi>
     </math>
     (Eq.
     <a class="open-asset-modal" data-target="#ModalSchemeS1_E13" data-toggle="modal" href="">
      <span class="sci-ico-fileFormula">
      </span>
      13
     </a>
     ), na situação na qual a hipótese de vínculo entre a velocidade do centro de massa e a velocidade tangencial não é respeitada (
     <math display="inline">
      <mrow>
       <mi>
        f
       </mi>
       <mo>
        ≠
       </mo>
       <mn>
        1
       </mn>
      </mrow>
     </math>
     ).
    </p>
    <h1 class="articleSectionTitle">
     4. Conclusão
    </h1>
    <p>
     Neste trabalho mostramos que os modelos de aprendizado de máquina aqui vistos conseguem “aprender física” no sentido restrito de reproduzir com muita acurácia os padrões nos dados fornecidos, baseando-se na mesma informação física dos modelos teóricos (mesmo conjunto de variáveis). Porém, tais modelos não são capazes de generalizar além dos padrões aprendidos nem intuir sobre as limitações do modelo. Pelo fato dos algoritmos serem agnósticos aos conceitos físicos, é muito desafiador extrair aprendizados mais profundos de suas predições (o que configura uma área própria de pesquisa em inteligência artificial [
     <span class="ref">
      <sup class="xref xrefblue">
       20
      </sup>
      <span class="refCtt closed">
       <span>
        [20] M. Popolin Neto e F.V. Paulovich, IEEE Trans. Vis. Comput. Graph. 27, 1427 (2021).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       21
      </sup>
      <span class="refCtt closed">
       <span>
        [21] P.A. Angelov, E.A. Soares, R. Jiang, N.I. Arnold e P.M. Atkinson, WIREs Data Mining and Knowledge Discovery 11, e1424 (2021).
       </span>
      </span>
     </span>
     ]). Alguns modelos possuem formulações matemáticas características que podem ser úteis para uma compreensão mais ampla, normalmente nos denominados regressores paramétricos (como a regressão linear, que assume uma função linear como padrão nos dados). Uma vez que se descobrem os coeficientes da função previamente assumida que melhor descrevem os dados, pode-se estabelecer relação deles com a realidade física. Um exemplo clássico disso é a primeira Lei de Ohm, na qual a relação fenomenológica entre a queda de tensão
     <i>
      V
     </i>
     e a corrente elétrica
     <i>
      I
     </i>
     que circula por um fio metálico é uma função linear do tipo
     <i>
      V=RI
     </i>
     , sendo que a constante
     <i>
      R
     </i>
     encontrada pela regressão linear de
     <i>
      V
     </i>
     e
     <i>
      I
     </i>
     tem significado físico de resistência elétrica. Por outro lado, modelos não-paramétricos podem alcançar desempenhos extremamente satisfatórios nas tarefas realizadas sem explicitamente entregarem nenhuma informação adicional (como redes neurais profundas). Independentemente dessas características, é importante notar que todos os algoritmos de aprendizado de máquina aprendem a reproduzir o padrão dos dados através dos próprios dados. Isto significa que em nenhum dos casos aqui discutidos foi feito um esforço deliberado para introduzir física aos modelos, como ocorreria em um paradigma de ciência computacional tradicional – toda a física está contida na seleção das
     <i>
      features
     </i>
     de entrada dos algoritmos.
    </p>
    <p>
     Uma vez que nos limitamos aqui a aplicação dos algoritmos como caixa-pretas, devemos destacar as utilidades e limitações de suas aplicações. Pelo contraste entre os modelos teóricos e de aprendizado de máquina, um pesquisador poderia concluir que as mesmas variáveis físicas selecionadas podem ser usadas para gerar um modelo mais acurado, o que é um teste indicativo sobre a validade das hipóteses assumidas no modelo físico – mas que exige cuidados com relação as instâncias de dados usadas para treinamento e teste (cuja separação pode gerar certo vazamento de informação entre as etapas, emulando mais informação do que o modelo deveria ter acesso). De uma perspectiva diferente, pesquisas que envolvam a análise de muitos dados (que podem ser rotulados por humanos em quantidade muito menor do que por um algoritmo automatizado) podem se valer dessas técnicas, por exemplo: a detecção de exoplanetas, [
     <span class="ref">
      <sup class="xref xrefblue">
       30
      </sup>
      <span class="refCtt closed">
       <span>
        [30] H. Valizadegan, M.J.S. Martinho, L.S. Wilkens, J.M. Jenkins, J.C. Smith, D.A. Caldwell, J.D. Twicken, P.C.L. Gerum, N. Walia, K. Hausknecht et al., The Astrophysical Journal 926, 120 (2022).
       </span>
      </span>
     </span>
     ]; a predição de ordem magnética em materiais bidimensionais [
     <span class="ref">
      <sup class="xref xrefblue">
       31
      </sup>
      <span class="refCtt closed">
       <span>
        [31] C.M. Acosta, E. Ogoshi, J.A. Souza e G.M. Dalpian, ACS Applied Materials &amp; Interfaces 14, 9418 (2022).
       </span>
      </span>
     </span>
     ]; e a análise de experimentos de altas energias [
     <span class="ref">
      <sup class="xref xrefblue">
       32
      </sup>
      <span class="refCtt closed">
       <span>
        [32] D. Guest, K. Cranmer e D. Whiteson, Annual Review of Nuclear and Particle Science 68, 161 (2018).
       </span>
      </span>
     </span>
     ,
     <span class="ref">
      <sup class="xref xrefblue">
       33
      </sup>
      <span class="refCtt closed">
       <span>
        [33] G. Karagiorgi, G. Kasieczka, S. Kravitz, B. Nachman e D. Shih, Nature Reviews Physics 4, 399 (2022).
       </span>
      </span>
     </span>
     ]. Em qualquer aplicação, como ferramentas de aprendizado automatizado, os algoritmos também podem falhar em suas previsões, seja devido ao sub-ajuste ou ao sobre-ajuste, ou pela própria natureza estatística de seu funcionamento.
    </p>
    <p>
     Os procedimentos metodológicos e as ferramentas aqui apresentadas são de fácil acesso e compreensão. Acreditamos ser muito importante para o estudante de física familiarizar-se com tais técnicas, acumulando assim os saberes dos diferentes paradigmas de se fazer ciência.
    </p>
    <p>
     Ensinar física às máquinas é ainda uma jornada em seu inicio. Diversos novos desdobramentos estão sendo pesquisados e construídos dessa interação interdisciplinar entre computação e física. Por enquanto podemos treinar o computador para ter um desempenho semelhante ou melhor do que Galileo teve ao analisar os dados do rolamento no plano inclinado. Contudo, as tarefas em que podemos fazer isso são apenas fragmentos de tudo aquilo que Galileo fez neste experimento. Dessa forma, apesar de máquinas poderem aprender física, elas ainda não são capazes de substituir físicos. Em vez disso, o aprendizado de máquina vem se mostrando uma ferramenta auxiliar de grande importância para o trabalho deles.
    </p>
   </div>
   <div class="articleSection" data-anchor="Agradecimentos">
    <h1 class="articleSectionTitle">
     Agradecimentos
    </h1>
    <p>
     O presente trabalho foi realizado com apoio da Coordenação de Aperfeiçoamento de Pessoal de Nível Superior – Brasil (CAPES) – Código de Financiamento 001. W.F. Espinosa-García agradece à Universidad de San Buenaventura-Medellín pelo suporte (projeto 449011-22.01-01P). G. M. Dalpian e J. N. B. Rodrigues agradecem ao CNPq pelo financiamento. Este trabalho também foi realizado no âmbito do Projeto Temático FAPESP 17/02317-2. Os autores agradecem aos estudantes da turma de Física II da UFOB Bárbara Beatriz Pedroza Santos, Camila de Jesus Vargas, Geovanna Sousa Bonifácio Magalhães, Lorena Vieira Soares, Rafael Sales Souza Farias e William Philip Leite de Castro pelo suporte na realização dos experimentos.
    </p>
   </div>
   <div class="articleSection" data-anchor="Apêndice">
    <h1 class="articleSectionTitle">
     Apêndice
    </h1>
    <a href="https://minio.scielo.br/documentstore/1806-9126/JS7GjGRH5HmCnqFZSpvFZHK/519cd725fcfeaabaa96811b53b320daab22d5304.pdf" target="_blank">
     A. Da presença de conteúdo de computação em cursos de física; B. Do rolamento no plano inclinado por formalismo Lagrangiano; C. Do algoritmo KNN.
    </a>
   </div>
   <div class="articleSection" data-anchor="Referências">
    <h1 class="articleSectionTitle">
     Referências
    </h1>
    <div class="ref-list">
     <ul class="refList">
      <li>
       <sup class="xref big">
        [1]
       </sup>
       <div>
        F. Ricci, L. Rokach e B. Shapira (eds), Recommender systems handbook (Springer, New York, 2015), 2 ed.
       </div>
      </li>
      <li>
       <sup class="xref big">
        [2]
       </sup>
       <div>
        G.R. Schleder, A.C.M. Padilha, C.M. Acosta, M. Costa e A. Fazzio, Journal of Physics: Materials 2, 032001 (2019).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [3]
       </sup>
       <div>
        O.N. Oliveira Jr e M.C.F. Oliveira, Front. Chem. 10, 930369 (2022).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [4]
       </sup>
       <div>
        S. Schmidt. Escola Superior Ilum busca cientísta do futuro, Revista FAPESP, junho de 2022.
       </div>
      </li>
      <li>
       <sup class="xref big">
        [5]
       </sup>
       <div>
        G. Galilei,
        <i>
         Dialogues Concerning Two New Sciences
        </i>
        (Macmillan, New York, 1914).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [6]
       </sup>
       <div>
        C.M. Ramos e J.R. Bonjorno,
        <i>
         Fisica: História e Cotidiano
        </i>
        (FTD, São Paulo, 2005).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [7]
       </sup>
       <div>
        H.M. Nussenzveig,
        <i>
         Curso de Física Básica: Mecânica
        </i>
        (Blucher, Rio de Janeiro, 2013).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [8]
       </sup>
       <div>
        A. Chaves e J.F. Sampaio,
        <i>
         Física Básica: Mecânica
        </i>
        (LTC, Rio de Janeiro, 2011).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [9]
       </sup>
       <div>
        R.L. Chaplin e M.G. Miller, American Journal of Physics 52, 1108 (1984).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [10]
       </sup>
       <div>
        R. Cross, European Journal of Physics 36, 065047 (2015).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [11]
       </sup>
       <div>
        M. Newman,
        <i>
         Computational Physics
        </i>
        (Createspace Independent Publishing Platform, North Charleston, 2012).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [12]
       </sup>
       <div>
        D. Walker,
        <i>
         Computational Physics
        </i>
        (Mercury Learning &amp; Information, Dulles, 2016).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [13]
       </sup>
       <div>
        P.O.J. Scherer,
        <i>
         Computational Physics
        </i>
        (Springer, Cham, 2017).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [14]
       </sup>
       <div>
        G.R. Schleder e A. Fazzio, Revista Brasileira de Ensino de Física 43, e20200407 (2021).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [15]
       </sup>
       <div>
        A.L. Samuel, IBM Journal of Research and Development 3, 210 (1959).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [16]
       </sup>
       <div>
        K. Faceli, A.C. Lorena, J. Gama, T.A. Almeida e L.F.A.C.P.Carvalho,
        <i>
         Inteligência Artificial – Uma Abordagem de Aprendizado de Máquina
        </i>
        (LTC, Rio de Janeiro, 2021).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [17]
       </sup>
       <div>
        A. Géron,
        <i>
         Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow
        </i>
        (O’Reilly Media, Sebastopol, 2019), 2 ed.
       </div>
      </li>
      <li>
       <sup class="xref big">
        [18]
       </sup>
       <div>
        A. Burkov,
        <i>
         Machine learning engineering
        </i>
        (True Positive, Quebec, 2020).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [19]
       </sup>
       <div>
        M. Franklin e D. Lagnado, em: HCI International 2022 Posters, editado por StephanidisC., M. Antona e S. Ntoa (Springer, Cham, 2022).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [20]
       </sup>
       <div>
        M. Popolin Neto e F.V. Paulovich, IEEE Trans. Vis. Comput. Graph. 27, 1427 (2021).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [21]
       </sup>
       <div>
        P.A. Angelov, E.A. Soares, R. Jiang, N.I. Arnold e P.M. Atkinson, WIREs Data Mining and Knowledge Discovery 11, e1424 (2021).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [22]
       </sup>
       <div>
        S.M. Udrescu e M. Tegmark, Science Advances 6, eaay2631 (2020).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [23]
       </sup>
       <div>
        I. Sucholutsky e Schonlau M., Proceedings of the AAAI Conference on Artificial Intelligence 35, 9739 (2021).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [24]
       </sup>
       <div>
        L. A. Torrey e J. Shavlik, em: Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods and Techniques, editado por SoriaE., MartinJ., MagdalenaR., M. Martinez e A. Serrano (IGI Global, Hershey, 2009), v. 1.
       </div>
      </li>
      <li>
       <sup class="xref big">
        [25]
       </sup>
       <div>
        M. Kubat,
        <i>
         An introduction tomachine learning
        </i>
        (Springer International Publishing, Basel, 2015), 1 ed.
       </div>
      </li>
      <li>
       <sup class="xref big">
        [26]
       </sup>
       <div>
        H.F. Arruda, A. Benatti, C.H. Comin e L.F. Costa, Revista Brasileira de Ensino de Física 44, e20220101 (2022).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [27]
       </sup>
       <div>
        F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., Journal of Machine Learning Research 12, 2825 (2011).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [28]
       </sup>
       <div>
        G. van Rossum,
        <i>
         Python tutorial. Technical Report CS-R9526
        </i>
        (Centrum voor Wiskunde en Informatica, Amsterdam, 1995).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [29]
       </sup>
       <div>
        J. Cohen, Educational and Psychological Measurement 20, 37 (1960).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [30]
       </sup>
       <div>
        H. Valizadegan, M.J.S. Martinho, L.S. Wilkens, J.M. Jenkins, J.C. Smith, D.A. Caldwell, J.D. Twicken, P.C.L. Gerum, N. Walia, K. Hausknecht et al., The Astrophysical Journal 926, 120 (2022).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [31]
       </sup>
       <div>
        C.M. Acosta, E. Ogoshi, J.A. Souza e G.M. Dalpian, ACS Applied Materials &amp; Interfaces 14, 9418 (2022).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [32]
       </sup>
       <div>
        D. Guest, K. Cranmer e D. Whiteson, Annual Review of Nuclear and Particle Science 68, 161 (2018).
       </div>
      </li>
      <li>
       <sup class="xref big">
        [33]
       </sup>
       <div>
        G. Karagiorgi, G. Kasieczka, S. Kravitz, B. Nachman e D. Shih, Nature Reviews Physics 4, 399 (2022).
       </div>
      </li>
     </ul>
    </div>
   </div>
   <div>
    <h1>
    </h1>
    <div class="ref-list">
     <ul class="refList footnote">
      <li>
       <span class="xref big">
        1
       </span>
       <div>
        Em todos os casos discutidos, técnicas de pré-processamento da entrada podem ser usadas para adequar entradas simbólicas para numéricas, como o
        <i>
         Label Encoding
        </i>
        e o
        <i>
         One Hot Encoding
        </i>
        , etapa essa denominada de transformação de dados [
        <span class="ref">
         <sup class="xref xrefblue">
          16
         </sup>
         <span class="refCtt closed">
          <span>
           [16] K. Faceli, A.C. Lorena, J. Gama, T.A. Almeida e L.F.A.C.P.Carvalho, Inteligência Artificial – Uma Abordagem de Aprendizado de Máquina (LTC, Rio de Janeiro, 2021).
          </span>
         </span>
        </span>
        ]. Algoritmos de Árvore de Decisão podem ser diretamente implementados para usarem dados categóricos como entrada.
       </div>
      </li>
     </ul>
    </div>
   </div>
   <div class="articleSection" data-anchor="Datas de Publicação ">
    <h1 class="articleSectionTitle">
     Datas de Publicação
    </h1>
    <div class="row">
     <div class="col-md-12 col-sm-12">
      <ul class="articleTimeline">
       <li>
        <strong>
         Publicação nesta coleção
        </strong>
        <br/>
        05 Dez 2022
       </li>
       <li>
        <strong>
         Data do Fascículo
        </strong>
        <br/>
        2022
       </li>
      </ul>
     </div>
    </div>
   </div>
   <div class="articleSection" data-anchor="Histórico">
    <h1 class="articleSectionTitle">
     Histórico
    </h1>
    <div class="row">
     <div class="col-md-12 col-sm-12">
      <ul class="articleTimeline">
       <li>
        <strong>
         Recebido
        </strong>
        <br/>
        27 Jul 2022
       </li>
       <li>
        <strong>
         Revisado
        </strong>
        <br/>
        13 Set 2022
       </li>
       <li>
        <strong>
         Aceito
        </strong>
        <br/>
        12 Out 2022
       </li>
      </ul>
     </div>
    </div>
   </div>
   <section class="documentLicense">
    <div class="container-license">
     <div class="row">
      <div class="col-sm-3 col-md-2">
       <a href="https://creativecommons.org/licenses/by/4.0/deed.en" target="_blank" title="">
        <img alt="Creative Common - by 4.0 deed.en" src="https://licensebuttons.net/l/by/4.0/deed.en/88x31.png"/>
       </a>
      </div>
      <div class="col-sm-9 col-md-10">
       <a href="https://creativecommons.org/licenses/by/4.0/deed.en" target="_blank" title="">
        This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
       </a>
      </div>
     </div>
    </div>
   </section>
  </article>
 </div>
</div>