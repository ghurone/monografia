{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download Artigos SciELO\n",
    "\n",
    "Neste notebook é possível fazer download dos artigos da RBEF que podem ser encontrados no site de [SciELO](https://www.scielo.br/j/rbef/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from functions import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = Request()  # objeto de requisição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scielo_url = lambda x: urljoin('https://www.scielo.br', x)  # Função geradora de urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volumes_por_ano() -> dict[int:list]:\n",
    "    \"\"\"\n",
    "        Função que pega o link de cada volume da revista por ano.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário onde as chaves é o ano e os valores os links dos volumes do respectivo ano.\n",
    "    \"\"\"\n",
    "    req = request.get(scielo_url('j/rbef/grid'))\n",
    "    soup = BeautifulSoup(req.text, 'lxml', parse_only=SoupStrainer('tbody'))\n",
    "\n",
    "    links = {int(linha.td.text): [scielo_url(a['href']) for a in linha.find_all('a')] for linha in soup.find_all('tr')}\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artigos_por_volume(url: str, formato: str = 'html', idioma: str = 'pt') -> list[str]:\n",
    "    \"\"\"\n",
    "        Função que coleta o link de todos os artigos presentes no volume.\n",
    "\n",
    "    Args:\n",
    "        url (str): url do volume\n",
    "        formato (str, optional): Formato dos artigos. Defaults to 'html'.\n",
    "        idioma (str, optional): Idioma dos artigos. Defaults to 'pt'.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista com os links dos artigos deste volume.\n",
    "    \"\"\"\n",
    "    languages = {'pt': 'Português', 'en': 'Inglês', 'es': 'Espanhol'}\n",
    "    formatos = {'html': '/?lang=', 'pdf': '/?format=pdf&'}\n",
    "\n",
    "    lang = languages.get(idioma.lower())\n",
    "    form = formatos.get(formato.lower())\n",
    "\n",
    "    req = request.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(req.text, 'lxml', parse_only=SoupStrainer('a', attrs={'title': lang}))\n",
    "\n",
    "    return [scielo_url(a['href']) for a in soup.find_all('a') if 'abstract' not in a['href'] and form in a['href']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_do_artigo(url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "        Função que recebe uma url de um artigo e retorna uma string do seu html.\n",
    "\n",
    "    Args:\n",
    "        url (str): Url do artigo\n",
    "\n",
    "    Returns:\n",
    "        str: Retorna uma string do html da página do artigo.\n",
    "    \"\"\"\n",
    "    req = request.get(url)\n",
    "    \n",
    "    strainer = SoupStrainer('div', attrs={'class': 'articleTxt'})\n",
    "    \n",
    "    return BeautifulSoup(req.text, 'lxml', parse_only=strainer).prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "\n",
    "Nesta parte do notebook consiste no código de download dos artigos que estão no site da SciELO e que são da língua portugesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = volumes_por_ano() \n",
    "del volumes[2023]  # remove 2023 dos volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pasta `artigos_brutos` já existe!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(os.path.join(os.getcwd(), 'artigos_brutos')) # cria a pasta dos artigos brutos\n",
    "except FileExistsError:\n",
    "    print('A pasta `artigos_brutos` já existe!')\n",
    "\n",
    "try:\n",
    "    os.mkdir(os.path.join(os.getcwd(), 'artigos_brutos', 'SciELO')) # cria a pasta da SciELO dentro dos artigos brutos\n",
    "except FileExistsError:\n",
    "    print('A pasta `artigos_brutos\\SciELO` já existe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'artigos_brutos', 'SciELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c467f04a18c4c90a7444b6ef43faa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ano, urls in tqdm(volumes.items()):\n",
    "    \n",
    "    dir_path = os.path.join(path, str(ano))\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    n = 1\n",
    "    for volume_url in urls:\n",
    "        todos = artigos_por_volume(volume_url)\n",
    "        \n",
    "        for artigo_url in todos:\n",
    "            text = html_do_artigo(artigo_url)\n",
    "            titulo = f'artigo_{ano}_{str(n).rjust(3, \"0\")}.html'\n",
    "            path_save = os.path.join(dir_path, titulo)\n",
    "            \n",
    "            with open(path_save, 'w', encoding='utf8') as file:\n",
    "                file.write(text)\n",
    "            \n",
    "            n += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de fazer o download dos arquivos e salvá-los em uma pasta, podemos criar um Dataset para facilitar a navegação pelo conteúdo.\n",
    "\n",
    "Após a criação do dataset esses arquivos brutos são apagados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e668fd8da83d294f882a9b1881bcdf4fad9aa355d0eef119f9c689d241b75da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
